{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2seq__Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3k_AlAuKJqVA",
        "vmGWTdRmKRph",
        "S8RDrP4xKabR",
        "fC1T1EOoMTqC",
        "wqtZUQF2NuZE",
        "uXHW6sliPMEN",
        "cS0UgLiaKNej",
        "PkOiaLuJQMDG",
        "6DpC9zlzMcXp",
        "e1IhdBrgQYJr",
        "jmxIVOOQPWMu",
        "gp1cQOtpTKUN",
        "LGj7s0V4b5iI",
        "1Eb1r0ftb8H_",
        "DGugWUgvb-q5",
        "f1PBDedGcBFv",
        "t62J9yPft9e-",
        "DrGiu_YIcIQp",
        "a9E75azdcL7w",
        "F2YSUzlBuvPy",
        "IolEjxB1uxUu",
        "ZPSUIuZuuy40",
        "BKz6U8dFR-Tc",
        "C_kmtwSNRvhg"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fwPL0hIlGKoA"
      },
      "source": [
        "# <font color='red'>**Sequence to sequence implementation**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-nYHE_1ck2az"
      },
      "source": [
        "**There will be some functions that start with the word \"grader\" ex: grader_check_encoder(), grader_check_attention(), grader_onestepdecoder() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q3d7GeBMGbsJ"
      },
      "source": [
        "1. Download the **Italian** to **English** translation dataset from <a href=\"http://www.manythings.org/anki/ita-eng.zip\">here</a>\n",
        "\n",
        "2. You will find **ita.txt** file in that ZIP, \n",
        "you can read that data using python and preprocess that data. \n",
        "\n",
        "3. You have to implement an Encoder and Decoder architecture with  \n",
        "attention as discussed in the reference notebook.\n",
        "\n",
        "    * Encoder   - with 1 layer LSTM <br>\n",
        "    * Decoder   - with 1 layer LSTM<br>\n",
        "    * attention -  (Please refer the <a href= 'https://drive.google.com/file/d/1z_bnc-3aubKawbR6q8wyI6Mh5ho2R1aZ/view?usp=sharing'>**reference notebook**</a> to know more about the attention mechanism.)\n",
        "4. In Global attention, we have 3 types of scoring functions(as discussed in the reference notebook).\n",
        " As a part of this assignment **you need to create 3 models for each scoring function**\n",
        "<img src='https://i.imgur.com/iD2jZo3.png'>\n",
        "\n",
        "    * In model 1 you need to implemnt \"dot\" score function\n",
        "    * In model 2 you need to implemnt \"general\" score function\n",
        "    * In model 3 you need to implemnt \"concat\" score function.<br>\n",
        "    \n",
        " **Please do add the markdown titles for each model so that we can have a better look at the code and verify.**\n",
        "\n",
        "5. Using attention weights, you can plot the attention plots, \n",
        "please plot those for 2-3 examples. You can check about those in <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\">this</a>\n",
        "\n",
        "6. The attention layer has to be written by yourself only. \n",
        "The main objective of this assignment is to read and implement a paper on yourself so please do it yourself.  \n",
        "\n",
        "7. Please implement the class **onestepdecoder** as mentioned in the assignment instructions.\n",
        "\n",
        "8. You can use any tf.Keras highlevel API's to build and train the models. \n",
        " Check the reference notebook for better understanding.\n",
        "\n",
        "9. Use BLEU score as metric to evaluate your model. You can use any loss function you need.\n",
        "\n",
        "10. You have to use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
        "\n",
        "11. Resources:\n",
        "    a. Check the reference notebook\n",
        "    b. <a href=\"https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\">Resource 1</a>\n",
        "    c. <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention\">Resource 2</a>\n",
        "    d. <a href=\"https://stackoverflow.com/questions/44238154/what-is-the-difference-between-luong-attention-and-bahdanau-attention#:~:text=Luong%20attention%20used%20top%20hidden,hidden%20state%20at%20time%20t.\">Resource 3</a>\n",
        "    \n",
        "\n",
        "**Note 1:**  There are many blogs on the attention mechanisum which might be misleading you,\n",
        " so do read the references completly and after that only please check the internet.\n",
        " The best things is to read the research papers and try to implement it on your own. \n",
        "\n",
        "**Note 2:** To complete this assignment, the reference that are mentioned will be enough.\n",
        "\n",
        "**Note 3:** If you are starting this assignment, you might have completed minimum of 20 assignment.\n",
        " If  you are still not able to implement this algorithm you might have rushed in the previous assignments \n",
        "with out learning much and didn't spend your time productively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3k_AlAuKJqVA"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fU80Ao-AGaob",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "809235cf-6006-435d-edc8-3130403a5fca"
      },
      "source": [
        "!wget --header=\"Host: www.manythings.org\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.0.0 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://colab.research.google.com/\" --header=\"Cookie: __cfduid=df22880bb4f55c8fa346f3877f536184c1593838215\" --header=\"Connection: keep-alive\" \"http://www.manythings.org/anki/ita-eng.zip\" -c -O 'ita-eng.zip'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-09 03:24:53--  http://www.manythings.org/anki/ita-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 172.67.173.198, 104.24.109.196, 104.24.108.196, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|172.67.173.198|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7441562 (7.1M) [application/zip]\n",
            "Saving to: ‘ita-eng.zip’\n",
            "\n",
            "ita-eng.zip         100%[===================>]   7.10M  3.25MB/s    in 2.2s    \n",
            "\n",
            "2020-07-09 03:24:55 (3.25 MB/s) - ‘ita-eng.zip’ saved [7441562/7441562]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sEqYH05KZ89",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "3476a855-e09b-461e-c015-ac35183c9df5"
      },
      "source": [
        "!unzip ita-eng.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ita-eng.zip\n",
            "  inflating: ita.txt                 \n",
            "  inflating: _about.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFWMrooLaBi_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "path_to_file = 'ita.txt'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTMmKcuDOZa5",
        "colab_type": "text"
      },
      "source": [
        "Looking at dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmPJtd-9UpNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = open(\"ita.txt\", \"r\") "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx5oH8QELMhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.readlines()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdNJNlN-L8LZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "31ed6e6e-6251-48a0-b7e3-2e214e3995fa"
      },
      "source": [
        "data[:5]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi.\\tCiao!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #607364 (Cero)\\n',\n",
              " 'Run!\\tCorri!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906347 (Guybrush88)\\n',\n",
              " 'Run!\\tCorra!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906348 (Guybrush88)\\n',\n",
              " 'Run!\\tCorrete!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906350 (Guybrush88)\\n',\n",
              " 'Who?\\tChi?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2083030 (CK) & #2126402 (Guybrush88)\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A61RwHstOgAt",
        "colab_type": "text"
      },
      "source": [
        "Using pandas since the values seem to be seperated by tab space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af2YG8A1N1pR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('ita.txt',sep = '\\t', header = None)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jhon2ShjN5LE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "aed5b532-8f62-4392-c8c0-a8e2fe66b470"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao!</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corri!</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corra!</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Correte!</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who?</td>\n",
              "      <td>Chi?</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0         1                                                  2\n",
              "0   Hi.     Ciao!  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
              "1  Run!    Corri!  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
              "2  Run!    Corra!  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
              "3  Run!  Correte!  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
              "4  Who?      Chi?  CC-BY 2.0 (France) Attribution: tatoeba.org #2..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDo11BeSQNO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(2,axis=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvJwyM2dQQ4L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "e013c2d5-0432-4fc5-c07c-2ced1c824b5e"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corri!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corra!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Correte!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who?</td>\n",
              "      <td>Chi?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0         1\n",
              "0   Hi.     Ciao!\n",
              "1  Run!    Corri!\n",
              "2  Run!    Corra!\n",
              "3  Run!  Correte!\n",
              "4  Who?      Chi?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vmGWTdRmKRph"
      },
      "source": [
        "# Preprocess data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag1QuKwk9I2T",
        "colab_type": "text"
      },
      "source": [
        "Codes taken from https://www.tensorflow.org/tutorials/text/nmt_with_attention with minor changes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy3gkgwjd_Sy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtrmfLH_YTcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "import unicodedata\n",
        "import re\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHXoSzgXaMtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset(data):\n",
        "\n",
        "  eng_ = [preprocess_sentence(w) for w in tqdm(data[0])]\n",
        "  ita_ = [preprocess_sentence(w) for w in tqdm(data[1])]\n",
        "\n",
        "  return eng_, ita_"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgMWezjFaPjy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6b77a703-b9f5-43d3-8367-532d13ebbf30"
      },
      "source": [
        "import io\n",
        "eng, ita = create_dataset(df)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 340432/340432 [00:06<00:00, 53195.86it/s]\n",
            "100%|██████████| 340432/340432 [00:07<00:00, 48385.03it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7qzAiqE8Obm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "07ceb35f-3d47-4373-873b-0cbfc6283701"
      },
      "source": [
        "print(eng[0])\n",
        "print(ita[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> hi . <end>\n",
            "<start> ciao ! <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eETpMVSNYVKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbtvBRbo77bv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def load_dataset(data):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(data)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFwBxeuz-f-7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1dcf4508-5cd7-4d12-f77c-13628df98567"
      },
      "source": [
        "import tensorflow as tf\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(df)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 340432/340432 [00:06<00:00, 52064.58it/s]\n",
            "100%|██████████| 340432/340432 [00:06<00:00, 48774.56it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuCFRDpjXwVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocqlG1kQX4Su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S8RDrP4xKabR"
      },
      "source": [
        "# Implement custom encoder decoder and attention layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A45uc0JILMlV"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lx_5NA24KzRp",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns output sequence\n",
        "    '''\n",
        "\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "\n",
        "      #Initialize Embedding layer\n",
        "      #Intialize Encoder LSTM layer\n",
        "\n",
        "      super().__init__()\n",
        "      self.inp_vocab_size = inp_vocab_size\n",
        "      self.embedding_size = embedding_size\n",
        "      self.lstm_size = lstm_size\n",
        "      self.input_length = input_length\n",
        "      self.embedding = tf.keras.layers.Embedding(input_dim=self.inp_vocab_size, output_dim=self.embedding_size, input_length=self.input_length,mask_zero=True, name=\"embedding_layer_encoder\")\n",
        "      self.lstm = tf.keras.layers.LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
        "\n",
        "    def call(self,input_sequence,states):\n",
        "      '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "          returns -- All encoder_outputs, last time steps hidden and cell state\n",
        "      '''\n",
        "      embed_output = self.embedding(input_sequence)\n",
        "      lstm_output, lstm_state_h, lstm_state_c = self.lstm(embed_output, initial_state=states)\n",
        "      return lstm_output, lstm_state_h,lstm_state_c\n",
        "\n",
        "    def initialize_states(self,batch_size):\n",
        "      '''\n",
        "      Given a batch size it will return intial hidden state and intial cell state.\n",
        "      If batch size is 32- Hidden state shape is [32,lstm_units], cell state shape is [32,lstm_units]\n",
        "      '''\n",
        "      return [tf.zeros((batch_size, self.lstm_size)) ,  tf.zeros((batch_size, self.lstm_size))]\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4ub9aN-hK244"
      },
      "source": [
        "<font color='cyan'>**Grader function - 1**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wRoe65b9LB0D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9552436e-0b01-4818-b314-eb69c6b1b83b"
      },
      "source": [
        "def grader_check_encoder():\n",
        "    vocab_size=10\n",
        "    embedding_size=20\n",
        "    lstm_size=32\n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
        "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
        "    initial_state=encoder.initialize_states(batch_size)\n",
        "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
        "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
        "    return True\n",
        "print(grader_check_encoder())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTx6VKs6t_X0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lXn278lhLYRM"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ab5SNdPZLlur",
        "colab": {}
      },
      "source": [
        "#concat code from here https://www.tensorflow.org/tutorials/text/nmt_with_attention. Dot and general codes follow same approach\n",
        "\n",
        "class Attention(tf.keras.layers.Layer):\n",
        "  '''\n",
        "    Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
        "  '''\n",
        "  def __init__(self,scoring_function, att_units):\n",
        "\n",
        "\n",
        "    # Please go through the reference notebook and research paper to complete the scoring functions\n",
        "    super().__init__()\n",
        "    self.scoring_function = scoring_function\n",
        "\n",
        "    if self.scoring_function=='dot':\n",
        "      # Intialize variables needed for Dot score function here\n",
        "      pass\n",
        "    elif scoring_function == 'general':\n",
        "      # Intialize variables needed for General score function here\n",
        "      self.W = tf.keras.layers.Dense(att_units)\n",
        "      pass\n",
        "    elif scoring_function == 'concat':\n",
        "      # Intialize variables needed for Concat score function here\n",
        "      self.W = tf.keras.layers.Dense(att_units)\n",
        "      self.V = tf.keras.layers.Dense(1)\n",
        "      pass\n",
        "  \n",
        "  \n",
        "  def call(self,decoder_hidden_state,encoder_output):\n",
        "    '''\n",
        "      Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
        "      * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
        "        Multiply the score function with your encoder_outputs to get the context vector.\n",
        "        Function returns context vector and attention weights(softmax - scores)\n",
        "    '''\n",
        "\n",
        "    decoder_hidden_state_ = tf.expand_dims(decoder_hidden_state, 1)\n",
        "\n",
        "    # encoder shape = (batch_size,input_length,att_units)\n",
        "    # decoder shape = (batch_size,1,att_units)\n",
        "    # matmul with transpose of decoder.encoder shape = (batch_size,1,input_length)\n",
        "    # addition decoder+encoder shape = (batch_size,input_length,1)\n",
        "    # return in shape (batch_size,input_length,1)\n",
        "\n",
        "    # attention weights and context vector \n",
        "\n",
        "    if self.scoring_function == 'dot':\n",
        "        # Implement Dot score function here\n",
        "        score = tf.matmul(decoder_hidden_state_, encoder_output, transpose_b=True) \n",
        "        attention_weights = tf.nn.softmax(score, axis=2)                 # axis 2 will have input\n",
        "        attention_weights = tf.transpose(attention_weights, [0, 2, 1])   # swapping axes to required shape \n",
        "        context_vector = tf.matmul(score, encoder_output)                \n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)           # dropping the extra dimension\n",
        "        return context_vector, attention_weights  \n",
        "\n",
        "    elif self.scoring_function == 'general':\n",
        "        # Implement General score function here\n",
        "        score = tf.matmul(decoder_hidden_state_, self.W(encoder_output), transpose_b=True) \n",
        "        attention_weights = tf.nn.softmax(score, axis=2)                 \n",
        "        attention_weights = tf.transpose(attention_weights, [0, 2, 1])   \n",
        "        context_vector = tf.matmul(score, encoder_output)                \n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "    elif self.scoring_function == 'concat':\n",
        "        # Implement General score function here\n",
        "        score = self.V(tf.nn.tanh(self.W(decoder_hidden_state_) + self.W(encoder_output)))\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        context_vector = attention_weights * encoder_output\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        return context_vector, attention_weights  \n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ExQDlxI9LuqK"
      },
      "source": [
        "<font color='cyan'>**Grader function - 2**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "51x50h_TLrl9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "6f55ab28-4e14-4ba7-b974-a1df99415116"
      },
      "source": [
        "def grader_check_attention(scoring_fun):\n",
        "    input_length=10\n",
        "    vocab_size=10\n",
        "    batch_size=16\n",
        "    att_units=32\n",
        "    state_h=tf.random.uniform(shape=[batch_size,att_units])\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,att_units])\n",
        "    attention=Attention(scoring_fun,att_units)\n",
        "    context_vector,attention_weights=attention(state_h,encoder_output)\n",
        "    assert(context_vector.shape==(batch_size,att_units) and attention_weights.shape==(batch_size,input_length,1))\n",
        "    return True\n",
        "print(grader_check_attention('dot'))\n",
        "print(grader_check_attention('general'))\n",
        "print(grader_check_attention('concat'))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ic-FNEbfL2DN"
      },
      "source": [
        "## OneStepDecoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kc8m7lmOL097",
        "colab": {}
      },
      "source": [
        "#https://www.tensorflow.org/tutorials/text/nmt_with_attention concat and output reshape taken from here\n",
        "\n",
        "class OneStepDecoder(tf.keras.Model):\n",
        "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "\n",
        "      # Initialize decoder embedding layer, LSTM and any other objects needed\n",
        "      super().__init__()\n",
        "      self.tar_vocab_size = tar_vocab_size\n",
        "      self.embedding_dim = embedding_dim\n",
        "      self.input_length = input_length\n",
        "      self.dec_units = dec_units\n",
        "      self.score_fun = score_fun\n",
        "      self.att_units = att_units\n",
        "      self.embedding = tf.keras.layers.Embedding(input_dim=self.tar_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, name=\"embedding_layer_encoder\")\n",
        "      self.LSTM = tf.keras.layers.LSTM(self.dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "      self.dense = tf.keras.layers.Dense(tar_vocab_size)\n",
        "      self.attention = Attention(self.score_fun, self.att_units)\n",
        "\n",
        "  def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
        "    '''\n",
        "        One step decoder mechanisim step by step:\n",
        "      A. Pass the input_to_decoder to the embedding layer and then get the output(1,1,embedding_dim)\n",
        "      B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
        "      C. Concat the context vector with the step A output\n",
        "      D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
        "      E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
        "      F. Return the states from step D, output from Step E, attention weights from Step -B\n",
        "    '''\n",
        "    embed_output = self.embedding(input_to_decoder)\n",
        "\n",
        "    context_vector,attention_weights=self.attention(state_h,encoder_output)\n",
        "\n",
        "    concat = tf.concat([tf.expand_dims(context_vector, 1),embed_output],axis=-1)\n",
        "\n",
        "    decoder_output, state_h, state_c = self.LSTM(concat, initial_state=[state_h,state_c])\n",
        "\n",
        "    output = tf.reshape(decoder_output, (-1, decoder_output.shape[2]))\n",
        "\n",
        "    out = self.dense(output)\n",
        "\n",
        "    return out, state_h, state_c, attention_weights, context_vector"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R_I8I4EIMAXq"
      },
      "source": [
        "<font color='cyan'>**Grader function - 3**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uLEXhChnMC1k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "b5741d11-47a9-4e81-f2e8-0d3a443d92fe"
      },
      "source": [
        "def grader_onestepdecoder(score_fun):\n",
        "    vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=10\n",
        "    dec_units=16 \n",
        "    att_units=16\n",
        "    batch_size=32\n",
        "    onestepdecoder=OneStepDecoder(vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
        "    input_to_decoder=tf.random.uniform(shape=(batch_size,1),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    output,state_h,state_c,attention_weights,context_vector=onestepdecoder(input_to_decoder,encoder_output,state_h,state_c)\n",
        "    assert(output.shape==(batch_size,vocab_size))\n",
        "    assert(state_h.shape==(batch_size,dec_units))\n",
        "    assert(state_c.shape==(batch_size,dec_units))\n",
        "    assert(attention_weights.shape==(batch_size,input_length,1))\n",
        "    assert(context_vector.shape==(batch_size,dec_units))\n",
        "    return True\n",
        "    \n",
        "print(grader_onestepdecoder('dot'))\n",
        "print(grader_onestepdecoder('general'))\n",
        "print(grader_onestepdecoder('concat'))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6FHrurjUMGAi"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NV-x31rj6Hc4",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,out_vocab_size, embedding_dim, output_length, dec_units ,score_fun ,att_units):\n",
        "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
        "      super().__init__()\n",
        "      self.out_vocab_size = out_vocab_size\n",
        "      self.embedding_dim = embedding_dim\n",
        "      self.output_length = output_length\n",
        "      self.dec_units = dec_units\n",
        "      self.score_fun = score_fun\n",
        "      self.att_units = att_units\n",
        "      self.onestepdecoder=OneStepDecoder(out_vocab_size, embedding_dim, output_length, dec_units ,score_fun ,att_units)\n",
        "      self.embedding = tf.keras.layers.Embedding(input_dim=self.out_vocab_size, output_dim=self.embedding_dim, input_length=output_length, mask_zero=True, name=\"embedding_layer_decoder\")\n",
        "      self.lstm = tf.keras.layers.LSTM(self.dec_units, return_sequences=True, return_state=True, name=\"Encoder_LSTM\")\n",
        "        \n",
        "\n",
        "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
        "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
        "        #Create a tensor array as shown in the reference notebook\n",
        "        tensor = []    # I will rather initialize a list and append tensors to it then I will convert this list into tensor for my convinience\n",
        "        #Iterate till the length of the decoder input\n",
        "        for i in range(input_to_decoder.shape[1]):       # the input to decoder is in this dimension \n",
        "          input_to_decoder__ = tf.transpose(input_to_decoder)   # taking transpose because the of shape issues \n",
        "          input_to_decoder_ = input_to_decoder__[i]           # taking i'th value of the input length. Gives shape (32,)\n",
        "          input_to_decoder_ = tf.reshape(input_to_decoder_,[-1,1])   # reshape to (32,1) because of shape issues in onestepdecoder \n",
        "        # Call onestepdecoder for each token in decoder_input\n",
        "          output,state_h,state_c,attention_weights,context_vector=self.onestepdecoder(input_to_decoder_,encoder_output,decoder_hidden_state,decoder_cell_state)\n",
        "        # Store the output in tensorarray\n",
        "          tensor.append(output)\n",
        "        # Return the tensor array\n",
        "        tensor = tf.convert_to_tensor(tensor)  # converting list of tensors to tensor of tensors\n",
        "        tensor = tf.transpose(tensor, [1, 0, 2])   # interchanging dimensions because tensor shape is (11,32,13) .Proper output should be (32,11,13)\n",
        "        return tensor"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FxrL-P8bMJH6"
      },
      "source": [
        "<font color='cyan'>**Grader function - 4**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rtbx6onFMJXb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "065ec9e9-c678-4317-8d3a-b5f723e4b282"
      },
      "source": [
        "def grader_decoder(score_fun):\n",
        "    out_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=10\n",
        "    output_length=11\n",
        "    dec_units=16 \n",
        "    att_units=16\n",
        "    batch_size=32\n",
        "    \n",
        "    target_sentences=tf.random.uniform(shape=(batch_size,output_length),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    \n",
        "    decoder=Decoder(out_vocab_size, embedding_dim, output_length, dec_units ,score_fun ,att_units)\n",
        "    output=decoder(target_sentences,encoder_output, state_h, state_c)\n",
        "    assert(output.shape==(batch_size,output_length,out_vocab_size))\n",
        "    return True\n",
        "print(grader_decoder('dot'))\n",
        "print(grader_decoder('general'))\n",
        "print(grader_decoder('concat'))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fC1T1EOoMTqC"
      },
      "source": [
        "## Encoder Decoder model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FfqBIe20MT3D",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, Softmax, RNN, Dense, Embedding, LSTM\n",
        "\n",
        "class encoder_decoder(tf.keras.Model):\n",
        "  def __init__(self, encoder_inputs_length, decoder_inputs_length, output_vocab_size, score):\n",
        "    #Intialize objects from encoder decoder\n",
        "    super().__init__()\n",
        "    self.score = score\n",
        "    self.encoder = Encoder(inp_vocab_size=len(inp_lang.word_index)+1, embedding_size=20, input_length=encoder_inputs_length, lstm_size=16)\n",
        "    self.decoder = Decoder(out_vocab_size=len(targ_lang.word_index)+1, embedding_dim=20, output_length=decoder_inputs_length, dec_units=16, score_fun=self.score, att_units=16)\n",
        "    self.dense   = Dense(len(targ_lang.word_index)+1, activation='softmax')\n",
        "\n",
        "  def call(self,data):\n",
        "    input_to_encoder, input_to_decoder = data[0], data[1]\n",
        "    #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
        "    initial_state=self.encoder.initialize_states(batch_size=64)\n",
        "    encoder_output, encoder_h, encoder_c = self.encoder(input_to_encoder,initial_state)\n",
        "\n",
        "    # Decoder initial states are encoder final states, Initialize it accordingly\n",
        "    #dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * 128, 1)\n",
        "    # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
        "    decoder_output = self.decoder(input_to_decoder, encoder_output, encoder_h, encoder_c)\n",
        "    output = self.dense(decoder_output)\n",
        "\n",
        "    # return the decoder output\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE-1Pb-maZUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model  = encoder_decoder(encoder_inputs_length=30,decoder_inputs_length=20,output_vocab_size=len(targ_lang.word_index)+1, score='dot') # wont be using this approach"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WVRxB-FDMJWL"
      },
      "source": [
        "## Custom loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QY_3izrXMs8y",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def custom_lossfunction(targets,logits):\n",
        "  # Custom loss function that will not consider the loss for padded zeros.\n",
        "  # Refer https://www.tensorflow.org/tutorials/text/nmt_with_attention#define_the_optimizer_and_the_loss_function same code used\n",
        "  mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "  loss_ = loss_object(targets, logits)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zmrq0MhVP9Je",
        "colab_type": "text"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fgyWwZWeMxGQ",
        "colab": {}
      },
      "source": [
        "# Implement teacher forcing while training your model. You can do it two ways.\n",
        "# Prepare your data, encoder_input,decoder_input and decoder_output\n",
        "# if decoder input is \n",
        "# <start> Hi how are you\n",
        "# decoder output should be\n",
        "# Hi How are you <end>\n",
        "# i.e when you have send <start>-- decoder predicted Hi, 'Hi' decoder predicted 'How' .. e.t.c\n",
        "# from https://www.tensorflow.org/tutorials/text/nmt_with_attention#training with minor changes\n",
        "\n",
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden_h, enc_hidden_c = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden_h, dec_hidden_c = enc_hidden_h, enc_hidden_c\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * 128, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in tqdm(range(1, targ.shape[1])):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden_h, dec_hidden_c, _, _ = onestepdecoder(dec_input,enc_output, dec_hidden_h, dec_hidden_c)\n",
        "\n",
        "      loss += custom_lossfunction(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + onestepdecoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss\n",
        "\n",
        "# or\n",
        " \n",
        "# model.fit([train_ita,train_eng],train_eng[:,1:]..)\n",
        "# Note: If you follow this approach some grader functions might return false and this is fine."
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wqtZUQF2NuZE"
      },
      "source": [
        "# Model-dot\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXHW6sliPMEN",
        "colab_type": "text"
      },
      "source": [
        "## Initialization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nov7qwFE36Tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(len(input_tensor_train))\n",
        "dataset = dataset.batch(128, drop_remainder=True)\n",
        "steps_per_epoch = len(input_tensor_train)//128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbGJIsBX3nxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(inp_vocab_size=len(inp_lang.word_index)+1, embedding_size=50, input_length=50, lstm_size=128)  \n",
        "decoder = Decoder(out_vocab_size=len(targ_lang.word_index)+1, embedding_dim=50, output_length=50, dec_units=128, score_fun='dot', att_units=128)\n",
        "onestepdecoder=OneStepDecoder(len(targ_lang.word_index)+1, 50, 50, 128 ,'dot' ,128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS0UgLiaKNej",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyL-oGEhHkIO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aec70e33-faae-4182-c060-4876f7175028"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sns89zeD3SAS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "24902758-e9d0-4951-ef54-ee3163e0cfe7"
      },
      "source": [
        "# from https://www.tensorflow.org/tutorials/text/nmt_with_attention#training with minor changes\n",
        "EPOCHS = 5\n",
        "import time\n",
        "checkpoint_dir = './content/gdrive/My Drive/Colab Notebooks/Seq2Seq checkpoiints/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=onestepdecoder)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_states(batch_size=128)\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 111/111 [00:39<00:00,  2.81it/s]\n",
            "100%|██████████| 111/111 [00:36<00:00,  3.02it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 0.6700\n",
            "Epoch 1 Batch 100 Loss 0.3592\n",
            "Epoch 1 Batch 200 Loss 0.3460\n",
            "Epoch 1 Batch 300 Loss 0.3350\n",
            "Epoch 1 Batch 400 Loss 0.3133\n",
            "Epoch 1 Batch 500 Loss 0.3213\n",
            "Epoch 1 Batch 600 Loss 0.3501\n",
            "Epoch 1 Batch 700 Loss 0.3276\n",
            "Epoch 1 Batch 800 Loss 0.3135\n",
            "Epoch 1 Batch 900 Loss 0.3124\n",
            "Epoch 1 Batch 1000 Loss 0.3092\n",
            "Epoch 1 Batch 1100 Loss 0.3079\n",
            "Epoch 1 Batch 1200 Loss 0.3082\n",
            "Epoch 1 Batch 1300 Loss 0.2945\n",
            "Epoch 1 Batch 1400 Loss 0.3155\n",
            "Epoch 1 Batch 1500 Loss 0.3090\n",
            "Epoch 1 Batch 1600 Loss 0.2869\n",
            "Epoch 1 Batch 1700 Loss 0.3049\n",
            "Epoch 1 Batch 1800 Loss 0.2904\n",
            "Epoch 1 Batch 1900 Loss 0.2790\n",
            "Epoch 1 Batch 2000 Loss 0.2807\n",
            "Epoch 1 Batch 2100 Loss 0.2680\n",
            "Epoch 1 Loss 0.3164\n",
            "Time taken for epoch 1390.4504945278168 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.2842\n",
            "Epoch 2 Batch 100 Loss 0.2779\n",
            "Epoch 2 Batch 200 Loss 0.2906\n",
            "Epoch 2 Batch 300 Loss 0.2680\n",
            "Epoch 2 Batch 400 Loss 0.2756\n",
            "Epoch 2 Batch 500 Loss 0.2681\n",
            "Epoch 2 Batch 600 Loss 0.2519\n",
            "Epoch 2 Batch 700 Loss 0.2770\n",
            "Epoch 2 Batch 800 Loss 0.2993\n",
            "Epoch 2 Batch 900 Loss 0.2563\n",
            "Epoch 2 Batch 1000 Loss 0.2659\n",
            "Epoch 2 Batch 1100 Loss 0.2568\n",
            "Epoch 2 Batch 1200 Loss 0.2570\n",
            "Epoch 2 Batch 1300 Loss 0.2604\n",
            "Epoch 2 Batch 1400 Loss 0.2488\n",
            "Epoch 2 Batch 1500 Loss 0.2269\n",
            "Epoch 2 Batch 1600 Loss 0.2415\n",
            "Epoch 2 Batch 1700 Loss 0.2413\n",
            "Epoch 2 Batch 1800 Loss 0.2285\n",
            "Epoch 2 Batch 1900 Loss 0.2357\n",
            "Epoch 2 Batch 2000 Loss 0.2273\n",
            "Epoch 2 Batch 2100 Loss 0.2118\n",
            "Epoch 2 Loss 0.2562\n",
            "Time taken for epoch 1223.832174539566 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.2088\n",
            "Epoch 3 Batch 100 Loss 0.2037\n",
            "Epoch 3 Batch 200 Loss 0.2220\n",
            "Epoch 3 Batch 300 Loss 0.2064\n",
            "Epoch 3 Batch 400 Loss 0.2043\n",
            "Epoch 3 Batch 500 Loss 0.2026\n",
            "Epoch 3 Batch 600 Loss 0.1995\n",
            "Epoch 3 Batch 700 Loss 0.1960\n",
            "Epoch 3 Batch 800 Loss 0.2152\n",
            "Epoch 3 Batch 900 Loss 0.2003\n",
            "Epoch 3 Batch 1000 Loss 0.1990\n",
            "Epoch 3 Batch 1100 Loss 0.2054\n",
            "Epoch 3 Batch 1200 Loss 0.1927\n",
            "Epoch 3 Batch 1300 Loss 0.1944\n",
            "Epoch 3 Batch 1400 Loss 0.1975\n",
            "Epoch 3 Batch 1500 Loss 0.1820\n",
            "Epoch 3 Batch 1600 Loss 0.1662\n",
            "Epoch 3 Batch 1700 Loss 0.1753\n",
            "Epoch 3 Batch 1800 Loss 0.1850\n",
            "Epoch 3 Batch 1900 Loss 0.2037\n",
            "Epoch 3 Batch 2000 Loss 0.1790\n",
            "Epoch 3 Batch 2100 Loss 0.1831\n",
            "Epoch 3 Loss 0.2011\n",
            "Time taken for epoch 1223.4508936405182 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.2696\n",
            "Epoch 4 Batch 100 Loss 0.2333\n",
            "Epoch 4 Batch 200 Loss 0.2014\n",
            "Epoch 4 Batch 300 Loss 0.2145\n",
            "Epoch 4 Batch 400 Loss 0.2002\n",
            "Epoch 4 Batch 500 Loss 0.1897\n",
            "Epoch 4 Batch 600 Loss 0.2124\n",
            "Epoch 4 Batch 700 Loss 0.2136\n",
            "Epoch 4 Batch 800 Loss 0.1815\n",
            "Epoch 4 Batch 900 Loss 0.1715\n",
            "Epoch 4 Batch 1000 Loss 0.1771\n",
            "Epoch 4 Batch 1100 Loss 0.1696\n",
            "Epoch 4 Batch 1200 Loss 0.1988\n",
            "Epoch 4 Batch 1300 Loss 0.1603\n",
            "Epoch 4 Batch 1400 Loss 0.2008\n",
            "Epoch 4 Batch 1500 Loss 0.1779\n",
            "Epoch 4 Batch 1600 Loss 0.1565\n",
            "Epoch 4 Batch 1700 Loss 0.1588\n",
            "Epoch 4 Batch 1800 Loss 0.1761\n",
            "Epoch 4 Batch 1900 Loss 0.1880\n",
            "Epoch 4 Batch 2000 Loss 0.1707\n",
            "Epoch 4 Batch 2100 Loss 0.1671\n",
            "Epoch 4 Loss 0.1895\n",
            "Time taken for epoch 1223.12153840065 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.1723\n",
            "Epoch 5 Batch 100 Loss 0.1614\n",
            "Epoch 5 Batch 200 Loss 0.1741\n",
            "Epoch 5 Batch 300 Loss 0.1475\n",
            "Epoch 5 Batch 400 Loss 0.1563\n",
            "Epoch 5 Batch 500 Loss 0.1576\n",
            "Epoch 5 Batch 600 Loss 0.1578\n",
            "Epoch 5 Batch 700 Loss 0.1620\n",
            "Epoch 5 Batch 800 Loss 0.1599\n",
            "Epoch 5 Batch 900 Loss 0.1660\n",
            "Epoch 5 Batch 1000 Loss 0.1533\n",
            "Epoch 5 Batch 1100 Loss 0.1565\n",
            "Epoch 5 Batch 1200 Loss 0.1475\n",
            "Epoch 5 Batch 1300 Loss 0.1460\n",
            "Epoch 5 Batch 1400 Loss 0.1705\n",
            "Epoch 5 Batch 1500 Loss 0.1599\n",
            "Epoch 5 Batch 1600 Loss 0.1356\n",
            "Epoch 5 Batch 1700 Loss 0.1509\n",
            "Epoch 5 Batch 1800 Loss 0.1669\n",
            "Epoch 5 Batch 1900 Loss 0.1360\n",
            "Epoch 5 Batch 2000 Loss 0.1591\n",
            "Epoch 5 Batch 2100 Loss 0.1508\n",
            "Epoch 5 Loss 0.1561\n",
            "Time taken for epoch 1222.7273924350739 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4VKqljudara",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "195a7c85-47ab-476f-b22c-5d808b799bb9"
      },
      "source": [
        "# from https://www.tensorflow.org/tutorials/text/nmt_with_attention#training with minor changes\n",
        "EPOCHS = 1\n",
        "import time\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=onestepdecoder)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_states(batch_size=128)\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 0.1544\n",
            "Epoch 1 Batch 100 Loss 0.1734\n",
            "Epoch 1 Batch 200 Loss 0.1467\n",
            "Epoch 1 Batch 300 Loss 0.1385\n",
            "Epoch 1 Batch 400 Loss 0.1433\n",
            "Epoch 1 Batch 500 Loss 0.1282\n",
            "Epoch 1 Batch 600 Loss 0.1249\n",
            "Epoch 1 Batch 700 Loss 0.1257\n",
            "Epoch 1 Batch 800 Loss 0.1416\n",
            "Epoch 1 Batch 900 Loss 0.1661\n",
            "Epoch 1 Batch 1000 Loss 0.1407\n",
            "Epoch 1 Batch 1100 Loss 0.1337\n",
            "Epoch 1 Batch 1200 Loss 0.1221\n",
            "Epoch 1 Batch 1300 Loss 0.1429\n",
            "Epoch 1 Batch 1400 Loss 0.1398\n",
            "Epoch 1 Batch 1500 Loss 0.1172\n",
            "Epoch 1 Batch 1600 Loss 0.1373\n",
            "Epoch 1 Batch 1700 Loss 0.1283\n",
            "Epoch 1 Batch 1800 Loss 0.1204\n",
            "Epoch 1 Batch 1900 Loss 0.1262\n",
            "Epoch 1 Batch 2000 Loss 0.1283\n",
            "Epoch 1 Batch 2100 Loss 0.1232\n",
            "Epoch 1 Loss 0.1378\n",
            "Time taken for epoch 1222.1849255561829 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H1HAolaix7K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "7dc06c92-8523-4995-ba7b-dcb53ad26168"
      },
      "source": [
        "# from https://www.tensorflow.org/tutorials/text/nmt_with_attention#training with minor changes\n",
        "EPOCHS = 1\n",
        "import time\n",
        "checkpoint_dir = '.extra/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=onestepdecoder)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_states(batch_size=128)\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 0.1257\n",
            "Epoch 1 Batch 100 Loss 0.1182\n",
            "Epoch 1 Batch 200 Loss 0.1139\n",
            "Epoch 1 Batch 300 Loss 0.1213\n",
            "Epoch 1 Batch 400 Loss 0.1174\n",
            "Epoch 1 Batch 500 Loss 0.1270\n",
            "Epoch 1 Batch 600 Loss 0.1192\n",
            "Epoch 1 Batch 700 Loss 0.1254\n",
            "Epoch 1 Batch 800 Loss 0.1414\n",
            "Epoch 1 Batch 900 Loss 0.1245\n",
            "Epoch 1 Batch 1000 Loss 0.1206\n",
            "Epoch 1 Batch 1100 Loss 0.1091\n",
            "Epoch 1 Batch 1200 Loss 0.1340\n",
            "Epoch 1 Batch 1300 Loss 0.1220\n",
            "Epoch 1 Batch 1400 Loss 0.1174\n",
            "Epoch 1 Batch 1500 Loss 0.1186\n",
            "Epoch 1 Batch 1600 Loss 0.1321\n",
            "Epoch 1 Batch 1700 Loss 0.1280\n",
            "Epoch 1 Batch 1800 Loss 0.1115\n",
            "Epoch 1 Batch 1900 Loss 0.1259\n",
            "Epoch 1 Batch 2000 Loss 0.1111\n",
            "Epoch 1 Batch 2100 Loss 0.1052\n",
            "Epoch 1 Loss 0.1205\n",
            "Time taken for epoch 1221.1852684020996 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50p4Ab9anEO3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "73eb2cad-9ebc-433e-d4ba-331c8df6e54e"
      },
      "source": [
        "# from https://www.tensorflow.org/tutorials/text/nmt_with_attention#training with minor changes\n",
        "EPOCHS = 1\n",
        "import time\n",
        "checkpoint_dir = './content/gdrive/My Drive/Colab Notebooks/Seq2Seq checkpoiints/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=onestepdecoder)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_states(batch_size=128)\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 0.1105\n",
            "Epoch 1 Batch 100 Loss 0.1105\n",
            "Epoch 1 Batch 200 Loss 0.1104\n",
            "Epoch 1 Batch 300 Loss 0.1098\n",
            "Epoch 1 Batch 400 Loss 0.1101\n",
            "Epoch 1 Batch 500 Loss 0.1044\n",
            "Epoch 1 Batch 600 Loss 0.1004\n",
            "Epoch 1 Batch 700 Loss 0.1069\n",
            "Epoch 1 Batch 800 Loss 0.1010\n",
            "Epoch 1 Batch 900 Loss 0.0985\n",
            "Epoch 1 Batch 1000 Loss 0.1023\n",
            "Epoch 1 Batch 1100 Loss 0.1206\n",
            "Epoch 1 Batch 1200 Loss 0.1095\n",
            "Epoch 1 Batch 1300 Loss 0.0999\n",
            "Epoch 1 Batch 1400 Loss 0.1287\n",
            "Epoch 1 Batch 1500 Loss 0.1050\n",
            "Epoch 1 Batch 1600 Loss 0.1158\n",
            "Epoch 1 Batch 1700 Loss 0.1038\n",
            "Epoch 1 Batch 1800 Loss 0.1072\n",
            "Epoch 1 Batch 1900 Loss 0.1023\n",
            "Epoch 1 Batch 2000 Loss 0.1068\n",
            "Epoch 1 Batch 2100 Loss 0.1188\n",
            "Epoch 1 Loss 0.1065\n",
            "Time taken for epoch 1216.8304238319397 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BDIM7G_s5Xx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "d9dfb9ae-60a4-4454-d2fe-6b98a9f1d7fd"
      },
      "source": [
        "# from https://www.tensorflow.org/tutorials/text/nmt_with_attention#training with minor changes\n",
        "EPOCHS = 1\n",
        "import time\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=onestepdecoder)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_states(batch_size=128)\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 0.0966\n",
            "Epoch 1 Batch 100 Loss 0.0948\n",
            "Epoch 1 Batch 200 Loss 0.1139\n",
            "Epoch 1 Batch 300 Loss 0.0973\n",
            "Epoch 1 Batch 400 Loss 0.0949\n",
            "Epoch 1 Batch 500 Loss 0.0931\n",
            "Epoch 1 Batch 600 Loss 0.1048\n",
            "Epoch 1 Batch 700 Loss 0.0969\n",
            "Epoch 1 Batch 800 Loss 0.0946\n",
            "Epoch 1 Batch 900 Loss 0.0982\n",
            "Epoch 1 Batch 1000 Loss 0.0947\n",
            "Epoch 1 Batch 1100 Loss 0.0889\n",
            "Epoch 1 Batch 1200 Loss 0.0789\n",
            "Epoch 1 Batch 1300 Loss 0.0816\n",
            "Epoch 1 Batch 1400 Loss 0.1003\n",
            "Epoch 1 Batch 1500 Loss 0.0896\n",
            "Epoch 1 Batch 1600 Loss 0.0901\n",
            "Epoch 1 Batch 1700 Loss 0.0872\n",
            "Epoch 1 Batch 1800 Loss 0.1124\n",
            "Epoch 1 Batch 1900 Loss 0.1090\n",
            "Epoch 1 Batch 2000 Loss 0.0968\n",
            "Epoch 1 Batch 2100 Loss 0.1051\n",
            "Epoch 1 Loss 0.0970\n",
            "Time taken for epoch 1216.9346754550934 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkOiaLuJQMDG",
        "colab_type": "text"
      },
      "source": [
        "## Model-1 summary:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRaRWvmmQQE3",
        "colab_type": "text"
      },
      "source": [
        "Model is trained for 9 epochs.\n",
        "\n",
        "Optimizer used is Adam with varying learning rate mentioned below.\n",
        "\n",
        "  *   First 6 epochs on default learning rate 0.01.\n",
        "  *   Next 3 epohs on a slower learning rate 0.001.\n",
        "\n",
        "Batch size used is 128.\n",
        "\n",
        "Embed size = Input length = Output length = 50\n",
        "\n",
        "Decoder units = Lstm units = Attention units = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6DpC9zlzMcXp"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z5NhESYyMW_t"
      },
      "source": [
        "Plot attention weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pkEY7SsBMtrC",
        "colab": {}
      },
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  #Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate code taken from same\n",
        "\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e1IhdBrgQYJr"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MP3kLZoPMvSu",
        "colab": {}
      },
      "source": [
        "def predict(input_sentence):\n",
        "  #https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate taken from here with minor changes\n",
        "  '''\n",
        "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "         Save the attention weights\n",
        "         And get the word using the tokenizer(word index) and then store it in a string.\n",
        "  E. Call plot_attention(#params)\n",
        "  F. Return the predicted sentence\n",
        "  '''\n",
        "  max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "  #attention_plot = []\n",
        "\n",
        "  sentence = preprocess_sentence(input_sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden,cell = tf.zeros((1, 128)),tf.zeros((1, 128))\n",
        "  enc_out, enc_hidden, enc_cell = encoder(inputs, [hidden,cell])\n",
        "\n",
        "\n",
        "  dec_hidden, dec_cell = enc_hidden, enc_cell\n",
        "  #dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 1)\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, dec_cell, attention_weights,_ = onestepdecoder(dec_input,enc_out, dec_hidden, dec_cell)\n",
        "                                                         \n",
        "    #output,dec_h,dec_c,attention_weights,_=onestepdecoder(input_to_decoder,encoder_output,dec_h,dec_c)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    #attention_plot.appeend(attention_weights.numpy())\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "  #attention_plot = np.asarray(attention_plot)\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lCBAgBMH0WV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention= predict(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmG9jifXKLE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh5C5qTBSpsU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "27e5e1a2-0df7-4eeb-d1ff-ec924f90086b"
      },
      "source": [
        "translate(df[1][50])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> spara ! <end>\n",
            "Predicted translation: get ! <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UPnX80OIG6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "07f960de-be99-4fa1-bebe-7c24ae526b64"
      },
      "source": [
        "translate(df[1][1000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> tom ha mentito . <end>\n",
            "Predicted translation: tom lied to lie . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eAXFOX2H0q9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "outputId": "8f474b6b-376e-4849-e39d-90a88ea1a56d"
      },
      "source": [
        "translate(df[1][200])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> chiamatemi . <end>\n",
            "Predicted translation: call me . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jmxIVOOQPWMu"
      },
      "source": [
        "## Calculate BLEU score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFbANMLMu2kP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pred_tensor(input_sentence):\n",
        "  max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "\n",
        "  #attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "  #attention_plot = []\n",
        "\n",
        "  sentence = preprocess_sentence(input_sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden,cell = tf.zeros((1, 128)),tf.zeros((1, 128))\n",
        "  enc_out, enc_hidden, enc_cell = encoder(inputs, [hidden,cell])\n",
        "\n",
        "\n",
        "  dec_hidden, dec_cell = enc_hidden, enc_cell\n",
        "  #dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 1)\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, dec_cell, _,_ = onestepdecoder(dec_input,enc_out, dec_hidden, dec_cell)\n",
        "                                                         \n",
        "    #output,dec_h,dec_c,attention_weights,_=onestepdecoder(input_to_decoder,encoder_output,dec_h,dec_c)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    #attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    #attention_plot.appeend(attention_weights.numpy())\n",
        "    #attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "    \n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "  #attention_plot = np.asarray(attention_plot)\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FUSfSfK5YP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import nltk.translate.bleu_score as bleu\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def get_bleu(inp_tensor, targ_tensor):\n",
        "  random_index = random.sample(range(1, 68086), 1000)\n",
        "  bleu_score = 0\n",
        "  for index in tqdm(random_index):\n",
        "    x = input_tensor_val[index]\n",
        "    y = target_tensor_val[index]\n",
        "    out=\" \"\n",
        "    for i in x:\n",
        "      if (i!=0 and i!=1 and i!=2):\n",
        "        out += inp_lang.index_word[i] + ' '\n",
        "    inp=\" \"\n",
        "    for i in y:\n",
        "      if (i!=0 and i!=1 and i!=2):\n",
        "        inp += targ_lang.index_word[i] + ' '\n",
        "    translated = pred_tensor(out)\n",
        "    translated = translated.split()\n",
        "    translated[-1] = ''\n",
        "    translated = ' '.join(translated)\n",
        "    bleu_score += bleu.sentence_bleu([translated.split(),], inp.split())\n",
        "  return bleu_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3Z7uaJqA242",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5b4477c6-8c9b-41b2-c695-22c9fa189986"
      },
      "source": [
        "get_bleu(input_tensor_val, target_tensor_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [01:08<00:00, 14.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "634.0815786012852"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp1cQOtpTKUN",
        "colab_type": "text"
      },
      "source": [
        "## Model-dot Results:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rcm2k9nTNI2",
        "colab_type": "text"
      },
      "source": [
        "Best loss is achieved at the last epoch having value 0.0970\n",
        "\n",
        "BLEU score on random 1000 datapoints of test data is 634.08"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SWg2ferDQvT3"
      },
      "source": [
        "# Model-General"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGj7s0V4b5iI",
        "colab_type": "text"
      },
      "source": [
        "## Training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_9eHnXIUy-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implement teacher forcing while training your model. You can do it two ways.\n",
        "# Prepare your data, encoder_input,decoder_input and decoder_output\n",
        "# if decoder input is \n",
        "# <start> Hi how are you\n",
        "# decoder output should be\n",
        "# Hi How are you <end>\n",
        "# i.e when you have send <start>-- decoder predicted Hi, 'Hi' decoder predicted 'How' .. e.t.c\n",
        "# from https://www.tensorflow.org/tutorials/text/nmt_with_attention#training with minor changes\n",
        "\n",
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden_h, enc_hidden_c = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden_h, dec_hidden_c = enc_hidden_h, enc_hidden_c\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * 128, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in tqdm(range(1, targ.shape[1])):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden_h, dec_hidden_c, _, _ = onestepdecoder(dec_input,enc_output, dec_hidden_h, dec_hidden_c)\n",
        "\n",
        "      loss += custom_lossfunction(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + onestepdecoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss\n",
        "\n",
        "# or\n",
        " \n",
        "# model.fit([train_ita,train_eng],train_eng[:,1:]..)\n",
        "# Note: If you follow this approach some grader functions might return false and this is fine."
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Eb1r0ftb8H_",
        "colab_type": "text"
      },
      "source": [
        "## Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99-3OYNNUyM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def custom_lossfunction(targets,logits):\n",
        "  # Custom loss function that will not consider the loss for padded zeros.\n",
        "  # Refer https://www.tensorflow.org/tutorials/text/nmt_with_attention#define_the_optimizer_and_the_loss_function same code used\n",
        "  mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "  loss_ = loss_object(targets, logits)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGugWUgvb-q5",
        "colab_type": "text"
      },
      "source": [
        "## Initialize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFaoI25zUavT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(len(input_tensor_train))\n",
        "dataset = dataset.batch(128, drop_remainder=True)\n",
        "steps_per_epoch = len(input_tensor_train)//128"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbOZU59PUbja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(inp_vocab_size=len(inp_lang.word_index)+1, embedding_size=50, input_length=50, lstm_size=128)  \n",
        "decoder = Decoder(out_vocab_size=len(targ_lang.word_index)+1, embedding_dim=50, output_length=50, dec_units=128, score_fun='general', att_units=128)\n",
        "onestepdecoder=OneStepDecoder(len(targ_lang.word_index)+1, 50, 50, 128 ,'general' ,128)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUANSiLFo4rZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "eed8cdcc-6615-4489-cc43-3ef9521a2fb7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1PBDedGcBFv",
        "colab_type": "text"
      },
      "source": [
        "## Start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keNluic5UfHD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4a30e2f7-eeec-4cf8-cee3-1fa05a84f86f"
      },
      "source": [
        "# from https://www.tensorflow.org/tutorials/text/nmt_with_attention#training with minor changes\n",
        "EPOCHS = 3\n",
        "import time\n",
        "checkpoint_dir = './content/gdrive/My Drive/Colab Notebooks/Seq2Seq checkpoiints/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=onestepdecoder)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_states(batch_size=128)\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 111/111 [00:37<00:00,  2.97it/s]\n",
            "100%|██████████| 111/111 [00:36<00:00,  3.03it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 0.6759\n",
            "Epoch 1 Batch 100 Loss 0.3792\n",
            "Epoch 1 Batch 200 Loss 0.3508\n",
            "Epoch 1 Batch 300 Loss 0.3414\n",
            "Epoch 1 Batch 400 Loss 0.3229\n",
            "Epoch 1 Batch 500 Loss 0.3216\n",
            "Epoch 1 Batch 600 Loss 0.3251\n",
            "Epoch 1 Batch 700 Loss 0.3484\n",
            "Epoch 1 Batch 800 Loss 0.3296\n",
            "Epoch 1 Batch 900 Loss 0.3286\n",
            "Epoch 1 Batch 1000 Loss 0.3203\n",
            "Epoch 1 Batch 1100 Loss 0.3168\n",
            "Epoch 1 Batch 1200 Loss 0.3105\n",
            "Epoch 1 Batch 1300 Loss 0.3219\n",
            "Epoch 1 Batch 1400 Loss 0.2970\n",
            "Epoch 1 Batch 1500 Loss 0.2798\n",
            "Epoch 1 Batch 1600 Loss 0.3041\n",
            "Epoch 1 Batch 1700 Loss 0.2960\n",
            "Epoch 1 Batch 1800 Loss 0.3100\n",
            "Epoch 1 Batch 1900 Loss 0.2838\n",
            "Epoch 1 Batch 2000 Loss 0.2827\n",
            "Epoch 1 Batch 2100 Loss 0.2931\n",
            "Epoch 1 Loss 0.3159\n",
            "Time taken for epoch 1702.172844171524 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.2600\n",
            "Epoch 2 Batch 100 Loss 0.2827\n",
            "Epoch 2 Batch 200 Loss 0.2623\n",
            "Epoch 2 Batch 300 Loss 0.2628\n",
            "Epoch 2 Batch 400 Loss 0.2668\n",
            "Epoch 2 Batch 500 Loss 0.2572\n",
            "Epoch 2 Batch 600 Loss 0.2746\n",
            "Epoch 2 Batch 700 Loss 0.2578\n",
            "Epoch 2 Batch 800 Loss 0.2711\n",
            "Epoch 2 Batch 900 Loss 0.2681\n",
            "Epoch 2 Batch 1000 Loss 0.2372\n",
            "Epoch 2 Batch 1100 Loss 0.2488\n",
            "Epoch 2 Batch 1200 Loss 0.2681\n",
            "Epoch 2 Batch 1300 Loss 0.2600\n",
            "Epoch 2 Batch 1400 Loss 0.2523\n",
            "Epoch 2 Batch 1500 Loss 0.2483\n",
            "Epoch 2 Batch 1600 Loss 0.2272\n",
            "Epoch 2 Batch 1700 Loss 0.2499\n",
            "Epoch 2 Batch 1800 Loss 0.2458\n",
            "Epoch 2 Batch 1900 Loss 0.2372\n",
            "Epoch 2 Batch 2000 Loss 0.2463\n",
            "Epoch 2 Batch 2100 Loss 0.2440\n",
            "Epoch 2 Loss 0.2587\n",
            "Time taken for epoch 1538.8191421031952 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.2463\n",
            "Epoch 3 Batch 100 Loss 0.2352\n",
            "Epoch 3 Batch 200 Loss 0.2299\n",
            "Epoch 3 Batch 300 Loss 0.2489\n",
            "Epoch 3 Batch 400 Loss 0.2484\n",
            "Epoch 3 Batch 500 Loss 0.2342\n",
            "Epoch 3 Batch 600 Loss 0.2275\n",
            "Epoch 3 Batch 700 Loss 0.2155\n",
            "Epoch 3 Batch 800 Loss 0.2386\n",
            "Epoch 3 Batch 900 Loss 0.2503\n",
            "Epoch 3 Batch 1000 Loss 0.2328\n",
            "Epoch 3 Batch 1100 Loss 0.2103\n",
            "Epoch 3 Batch 1200 Loss 0.2051\n",
            "Epoch 3 Batch 1300 Loss 0.2026\n",
            "Epoch 3 Batch 1400 Loss 0.2221\n",
            "Epoch 3 Batch 1500 Loss 0.2072\n",
            "Epoch 3 Batch 1600 Loss 0.2268\n",
            "Epoch 3 Batch 1700 Loss 0.2201\n",
            "Epoch 3 Batch 1800 Loss 0.1974\n",
            "Epoch 3 Batch 1900 Loss 0.1987\n",
            "Epoch 3 Batch 2000 Loss 0.1905\n",
            "Epoch 3 Batch 2100 Loss 0.2250\n",
            "Epoch 3 Loss 0.2207\n",
            "Time taken for epoch 1540.0128331184387 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZIyGqd5pbNu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f60a46da-9995-4449-a1bf-834d8c49304a"
      },
      "source": [
        "# from https://www.tensorflow.org/tutorials/text/nmt_with_attention#training with minor changes\n",
        "EPOCHS = 3\n",
        "import time\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=onestepdecoder)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_states(batch_size=128)\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 0.2008\n",
            "Epoch 1 Batch 100 Loss 0.1936\n",
            "Epoch 1 Batch 200 Loss 0.1936\n",
            "Epoch 1 Batch 300 Loss 0.1976\n",
            "Epoch 1 Batch 400 Loss 0.1992\n",
            "Epoch 1 Batch 500 Loss 0.1854\n",
            "Epoch 1 Batch 600 Loss 0.2097\n",
            "Epoch 1 Batch 700 Loss 0.2052\n",
            "Epoch 1 Batch 800 Loss 0.1754\n",
            "Epoch 1 Batch 900 Loss 0.1817\n",
            "Epoch 1 Batch 1000 Loss 0.1767\n",
            "Epoch 1 Batch 1100 Loss 0.1706\n",
            "Epoch 1 Batch 1200 Loss 0.1768\n",
            "Epoch 1 Batch 1300 Loss 0.1766\n",
            "Epoch 1 Batch 1400 Loss 0.1678\n",
            "Epoch 1 Batch 1500 Loss 0.1820\n",
            "Epoch 1 Batch 1600 Loss 0.1766\n",
            "Epoch 1 Batch 1700 Loss 0.1829\n",
            "Epoch 1 Batch 1800 Loss 0.1829\n",
            "Epoch 1 Batch 1900 Loss 0.1964\n",
            "Epoch 1 Batch 2000 Loss 0.1740\n",
            "Epoch 1 Batch 2100 Loss 0.2129\n",
            "Epoch 1 Loss 0.1882\n",
            "Time taken for epoch 1540.240258216858 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.2104\n",
            "Epoch 2 Batch 100 Loss 0.1835\n",
            "Epoch 2 Batch 200 Loss 0.1828\n",
            "Epoch 2 Batch 300 Loss 0.1800\n",
            "Epoch 2 Batch 400 Loss 0.1758\n",
            "Epoch 2 Batch 500 Loss 0.1725\n",
            "Epoch 2 Batch 600 Loss 0.1714\n",
            "Epoch 2 Batch 700 Loss 0.1684\n",
            "Epoch 2 Batch 800 Loss 0.1412\n",
            "Epoch 2 Batch 900 Loss 0.1769\n",
            "Epoch 2 Batch 1000 Loss 0.1723\n",
            "Epoch 2 Batch 1100 Loss 0.1714\n",
            "Epoch 2 Batch 1200 Loss 0.1499\n",
            "Epoch 2 Batch 1300 Loss 0.1744\n",
            "Epoch 2 Batch 1400 Loss 0.1705\n",
            "Epoch 2 Batch 1500 Loss 0.1637\n",
            "Epoch 2 Batch 1600 Loss 0.1648\n",
            "Epoch 2 Batch 1700 Loss 0.1598\n",
            "Epoch 2 Batch 1800 Loss 0.1508\n",
            "Epoch 1 Batch 0 Loss 0.2008\n",
            "Epoch 1 Batch 100 Loss 0.1936\n",
            "Epoch 1 Batch 200 Loss 0.1936\n",
            "Epoch 1 Batch 300 Loss 0.1976\n",
            "Epoch 1 Batch 400 Loss 0.1992\n",
            "Epoch 1 Batch 500 Loss 0.1854\n",
            "Epoch 1 Batch 600 Loss 0.2097\n",
            "Epoch 1 Batch 700 Loss 0.2052\n",
            "Epoch 1 Batch 800 Loss 0.1754\n",
            "Epoch 1 Batch 900 Loss 0.1817\n",
            "Epoch 1 Batch 1000 Loss 0.1767\n",
            "Epoch 1 Batch 1100 Loss 0.1706\n",
            "Epoch 1 Batch 1200 Loss 0.1768\n",
            "Epoch 1 Batch 1300 Loss 0.1766\n",
            "Epoch 1 Batch 1400 Loss 0.1678\n",
            "Epoch 1 Batch 1500 Loss 0.1820\n",
            "Epoch 1 Batch 1600 Loss 0.1766\n",
            "Epoch 1 Batch 1700 Loss 0.1829\n",
            "Epoch 1 Batch 1800 Loss 0.1829\n",
            "Epoch 1 Batch 1900 Loss 0.1964\n",
            "Epoch 1 Batch 2000 Loss 0.1740\n",
            "Epoch 1 Batch 2100 Loss 0.2129\n",
            "Epoch 1 Loss 0.1882\n",
            "Time taken for epoch 1540.240258216858 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.2104\n",
            "Epoch 2 Batch 100 Loss 0.1835\n",
            "Epoch 2 Batch 200 Loss 0.1828\n",
            "Epoch 2 Batch 300 Loss 0.1800\n",
            "Epoch 2 Batch 400 Loss 0.1758\n",
            "Epoch 2 Batch 500 Loss 0.1725\n",
            "Epoch 2 Batch 600 Loss 0.1714\n",
            "Epoch 2 Batch 700 Loss 0.1684\n",
            "Epoch 2 Batch 800 Loss 0.1412\n",
            "Epoch 2 Batch 900 Loss 0.1769\n",
            "Epoch 2 Batch 1000 Loss 0.1723\n",
            "Epoch 2 Batch 1100 Loss 0.1714\n",
            "Epoch 2 Batch 1200 Loss 0.1499\n",
            "Epoch 2 Batch 1300 Loss 0.1744\n",
            "Epoch 2 Batch 1400 Loss 0.1705\n",
            "Epoch 2 Batch 1500 Loss 0.1637\n",
            "Epoch 2 Batch 1600 Loss 0.1648\n",
            "Epoch 2 Batch 1700 Loss 0.1598\n",
            "Epoch 2 Batch 1800 Loss 0.1508\n",
            "Epoch 2 Batch 1900 Loss 0.1683\n",
            "Epoch 2 Batch 1900 Loss 0.1683\n",
            "Epoch 2 Batch 2000 Loss 0.1522\n",
            "Epoch 2 Batch 2000 Loss 0.1522\n",
            "Epoch 2 Batch 2100 Loss 0.1550\n",
            "Epoch 2 Batch 2100 Loss 0.1550\n",
            "Epoch 2 Loss 0.1658\n",
            "Time taken for epoch 1539.2130727767944 sec\n",
            "\n",
            "Epoch 2 Loss 0.1658\n",
            "Time taken for epoch 1539.2130727767944 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.1752\n",
            "Epoch 3 Batch 0 Loss 0.1752\n",
            "Epoch 3 Batch 100 Loss 0.1491\n",
            "Epoch 3 Batch 100 Loss 0.1491\n",
            "Epoch 3 Batch 200 Loss 0.1395\n",
            "Epoch 3 Batch 200 Loss 0.1395\n",
            "Epoch 3 Batch 300 Loss 0.1599\n",
            "Epoch 3 Batch 300 Loss 0.1599\n",
            "Epoch 3 Batch 400 Loss 0.1323\n",
            "Epoch 3 Batch 400 Loss 0.1323\n",
            "Epoch 3 Batch 500 Loss 0.1408\n",
            "Epoch 3 Batch 500 Loss 0.1408\n",
            "Epoch 3 Batch 600 Loss 0.1395\n",
            "Epoch 3 Batch 600 Loss 0.1395\n",
            "Epoch 3 Batch 700 Loss 0.1448\n",
            "Epoch 3 Batch 700 Loss 0.1448\n",
            "Epoch 3 Batch 800 Loss 0.1370\n",
            "Epoch 3 Batch 800 Loss 0.1370\n",
            "Epoch 3 Batch 900 Loss 0.1290\n",
            "Epoch 3 Batch 900 Loss 0.1290\n",
            "Epoch 3 Batch 1000 Loss 0.1341\n",
            "Epoch 3 Batch 1000 Loss 0.1341\n",
            "Epoch 3 Batch 1100 Loss 0.1385\n",
            "Epoch 3 Batch 1100 Loss 0.1385\n",
            "Epoch 3 Batch 1200 Loss 0.1576\n",
            "Epoch 3 Batch 1200 Loss 0.1576\n",
            "Epoch 3 Batch 1300 Loss 0.1461\n",
            "Epoch 3 Batch 1300 Loss 0.1461\n",
            "Epoch 3 Batch 1400 Loss 0.1496\n",
            "Epoch 3 Batch 1400 Loss 0.1496\n",
            "Epoch 3 Batch 1500 Loss 0.1529\n",
            "Epoch 3 Batch 1500 Loss 0.1529\n",
            "Epoch 3 Batch 1600 Loss 0.1373\n",
            "Epoch 3 Batch 1600 Loss 0.1373\n",
            "Epoch 3 Batch 1700 Loss 0.1453\n",
            "Epoch 3 Batch 1700 Loss 0.1453\n",
            "Epoch 3 Batch 1800 Loss 0.1329\n",
            "Epoch 3 Batch 1800 Loss 0.1329\n",
            "Epoch 3 Batch 1900 Loss 0.1328\n",
            "Epoch 3 Batch 1900 Loss 0.1328\n",
            "Epoch 3 Batch 2000 Loss 0.1304\n",
            "Epoch 3 Batch 2000 Loss 0.1304\n",
            "Epoch 3 Batch 2100 Loss 0.1639\n",
            "Epoch 3 Batch 2100 Loss 0.1639\n",
            "Epoch 3 Loss 0.1432\n",
            "Time taken for epoch 1538.2376861572266 sec\n",
            "\n",
            "Epoch 3 Loss 0.1432\n",
            "Time taken for epoch 1538.2376861572266 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mh06oaEUnRa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "33087a4e-c51f-4ee8-e4e5-f4a154afa211"
      },
      "source": [
        "# from https://www.tensorflow.org/tutorials/text/nmt_with_attention#training with minor changes\n",
        "EPOCHS = 1\n",
        "import time\n",
        "checkpoint_dir = '.extra/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=onestepdecoder)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_states(batch_size=128)\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 0.1282\n",
            "Epoch 1 Batch 100 Loss 0.1838\n",
            "Epoch 1 Batch 200 Loss 0.1353\n",
            "Epoch 1 Batch 300 Loss 0.1247\n",
            "Epoch 1 Batch 400 Loss 0.1397\n",
            "Epoch 1 Batch 500 Loss 0.1413\n",
            "Epoch 1 Batch 600 Loss 0.1396\n",
            "Epoch 1 Batch 700 Loss 0.1272\n",
            "Epoch 1 Batch 800 Loss 0.1314\n",
            "Epoch 1 Batch 900 Loss 0.1326\n",
            "Epoch 1 Batch 1000 Loss 0.1248\n",
            "Epoch 1 Batch 1100 Loss 0.1313\n",
            "Epoch 1 Batch 1200 Loss 0.1210\n",
            "Epoch 1 Batch 1300 Loss 0.1308\n",
            "Epoch 1 Batch 1400 Loss 0.1314\n",
            "Epoch 1 Batch 1500 Loss 0.1572\n",
            "Epoch 1 Batch 1600 Loss 0.1522\n",
            "Epoch 1 Batch 1700 Loss 0.1369\n",
            "Epoch 1 Batch 1800 Loss 0.1190\n",
            "Epoch 1 Batch 1900 Loss 0.1224\n",
            "Epoch 1 Batch 2000 Loss 0.1276\n",
            "Epoch 1 Batch 2100 Loss 0.1383\n",
            "Epoch 1 Loss 0.1356\n",
            "Time taken for epoch 1540.0749011039734 sec\n",
            "\n",
            "Epoch 1 Batch 0 Loss 0.1282\n",
            "Epoch 1 Batch 100 Loss 0.1838\n",
            "Epoch 1 Batch 200 Loss 0.1353\n",
            "Epoch 1 Batch 300 Loss 0.1247\n",
            "Epoch 1 Batch 400 Loss 0.1397\n",
            "Epoch 1 Batch 500 Loss 0.1413\n",
            "Epoch 1 Batch 600 Loss 0.1396\n",
            "Epoch 1 Batch 700 Loss 0.1272\n",
            "Epoch 1 Batch 800 Loss 0.1314\n",
            "Epoch 1 Batch 900 Loss 0.1326\n",
            "Epoch 1 Batch 1000 Loss 0.1248\n",
            "Epoch 1 Batch 1100 Loss 0.1313\n",
            "Epoch 1 Batch 1200 Loss 0.1210\n",
            "Epoch 1 Batch 1300 Loss 0.1308\n",
            "Epoch 1 Batch 1400 Loss 0.1314\n",
            "Epoch 1 Batch 1500 Loss 0.1572\n",
            "Epoch 1 Batch 1600 Loss 0.1522\n",
            "Epoch 1 Batch 1700 Loss 0.1369\n",
            "Epoch 1 Batch 1800 Loss 0.1190\n",
            "Epoch 1 Batch 1900 Loss 0.1224\n",
            "Epoch 1 Batch 2000 Loss 0.1276\n",
            "Epoch 1 Batch 2100 Loss 0.1383\n",
            "Epoch 1 Loss 0.1356\n",
            "Time taken for epoch 1540.0749011039734 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_AMm_ZEbEiq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ca2c7ea-3336-4671-9c98-3cc01c97d2e5"
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint('.extra/training_checkpoints'))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f421ea49be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t62J9yPft9e-",
        "colab_type": "text"
      },
      "source": [
        "## Model summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EDjAcd6uBTM",
        "colab_type": "text"
      },
      "source": [
        "Model is trained for 7 epochs.\n",
        "\n",
        "Optimizer used is Adam with varying learning rate mentioned below.\n",
        "\n",
        "  *   First 6 epochs on default learning rate 0.01.\n",
        "  *   Next 1 epoch on a slower learning rate 0.001.\n",
        "\n",
        "Batch size used is 128.\n",
        "\n",
        "Embed size = Input length = Output length = 50\n",
        "\n",
        "Decoder units = Lstm units = Attention units = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrGiu_YIcIQp",
        "colab_type": "text"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4RDabvEZz81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  #Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate code taken from same\n",
        "\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE3mi6zvaJgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(input_sentence):\n",
        "  #https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate taken from here with minor changes\n",
        "  '''\n",
        "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "         Save the attention weights\n",
        "         And get the word using the tokenizer(word index) and then store it in a string.\n",
        "  E. Call plot_attention(#params)\n",
        "  F. Return the predicted sentence\n",
        "  '''\n",
        "  max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "  #attention_plot = []\n",
        "\n",
        "  sentence = preprocess_sentence(input_sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden,cell = tf.zeros((1, 128)),tf.zeros((1, 128))\n",
        "  enc_out, enc_hidden, enc_cell = encoder(inputs, [hidden,cell])\n",
        "\n",
        "\n",
        "  dec_hidden, dec_cell = enc_hidden, enc_cell\n",
        "  #dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 1)\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, dec_cell, attention_weights,_ = onestepdecoder(dec_input,enc_out, dec_hidden, dec_cell)\n",
        "                                                         \n",
        "    #output,dec_h,dec_c,attention_weights,_=onestepdecoder(input_to_decoder,encoder_output,dec_h,dec_c)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    #attention_plot.appeend(attention_weights.numpy())\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "  #attention_plot = np.asarray(attention_plot)\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m2_J6TRaKMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention= predict(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZIXGgBCaRKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIlDB3sPaW9I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "1f3013bc-3c2b-42ae-b042-b26689549d66"
      },
      "source": [
        "translate(df[1][0])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> ciao ! <end>\n",
            "Predicted translation: hello ! <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBQR9olcbOO8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "outputId": "bf100b3e-d45f-4e4c-bea7-b57627a2563e"
      },
      "source": [
        "translate(df[1][200])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> chiamatemi . <end>\n",
            "Predicted translation: call me . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAKLCAYAAAAeg0qwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdrElEQVR4nO3deZSsB1nn8d9DViCEPSSArIILyHpHYDLsHhBFjwsji2ziEIYjioDgcBBhUDYFhjgwShwRIiIgLqggOwyO4iABDiBbwpKIrBEwKyEhz/xRFeh0bpZLkn67n/58zumT6rfqdj83dbu+/a5V3R0AYKYrLD0AAHD5EXoAGEzoAWAwoQeAwYQeAAYTegAYTOgBYDChB4DBhB4ABtt/6QFgN6mqDya5a3d/tao+lORCL03Z3bfausmAqYQettafJTlrffu1Sw4C7A7lWvcAMJd99AAwmE33sJCqunqSpye5e5LDsukX7+4+bIGxgGGEHpZzbJJbJHl5ki/mIg7MA/hO2UcPC6mqU7M6Av99S88CzGUfPSznk/EzCFzOvMjAch6b5NlVdeuq2m/pYYCZ7KOH5ZyQ5IpJ3pckVXW+O7tb/IFLTehhOX+S5KpJfikOxgMuJw7Gg4VU1RlJfrC7P7z0LMBc9tHDcj6S5NClhwBms0YPC6mqH87qgjm/luRDSc7eeH93f2WBsYBhhB4WUlXnbvh04w9iJWkH4wGXBQfjwXLuvvQAwHzW6AFgMAfjwYKq6geq6kVV9bdVdcR62U9U1W2Xng2YQehhIVV1ryT/lOR6Se6R1cVzkuSmSZ621FzALEIPy/mNJI/v7p9M8o0Ny9+Z5AcXmQgYR+hhObdM8oa9LP9Kkmts8SzAUEIPy/lKVpvtN7tdks9u8SzAUEIPy3llkt+uqutndR79/lV11yTPS3LsopMBYzi9DhZSVQckeVmSB2R1kZxz1/99ZZKHd/c3l5sOmELoYWFVdZOsNtdfIcn7u/v4hUcCBhF6WEhV/XqS53X3GZuWXzHJE7v7GctMBkwi9LCQqvpmkiO6+0ubll8zyZdc6x64LDgYD5ZTOf+b2ZzntlkdkQ9wqQn9QFV1s6p6e1X9wNKzcEFVdWpVnZJV5D9VVads+Dg9yZuSvGbZKYEpvHvdTA9Lcrckj0jyuGVHYS8ek9Xa/EuTPCXJv2+47xtJPtPd715iMGAe++iHqapK8pkkb0nyY0mu6zSt7Wl9zvw/dPfZS88CzCX0w1TV3ZP8WZLrJzk+yX/t7r9ediouTlUdnuTAjcu6+6SFxgEGsY9+noclee36lK1XrT9nG6qqQ6vq5VV1ZpJ/TfLpTR8Al5rQD1JVV07yU0n+aL3oj5L8aFVdbbmpuAjPT3LrJD+R5OtJHpTkiVld5/7+C84FDCL0s/x0kpO7+++SpLs/kNXm+wcsOhUX5j5JfrG735Tkm0mO6+4XJPlvSR616GQwTFVduaoeWlVXXXqWrSb0szwkySs2LXtFkodv/ShcAldLcuL69r8nueb69ruT/MdFJoK5fibJH2b1OrmrCP0QVfVdSe6eb2+2P88rk+ypqptv/VRcjE8mucn69keTPGB91sRPxQVz4LL20CQfzy5c8XHUPSykqh6X5Jvd/TtVdY8kf5PkgKx+AX9sd79o0QFhiKq6UZJPJPnBJP+Y5Hbd/ZElZ9pKQj9IVd0gyb/0Xp7UqrqB07W2t/XztyfJ8d39oaXngSmq6qlJ7tbd96yqP8/qZ+xXl55rqwj9IN4kBeCCqur4JM/s7pdV1U8nOTrJd+1tpWgioR+kqs5Ncp3u/vKm5TdM8pHuvvIyk3Fhquq2WR1bcVg2HTPT3U9aZCgYpKr+Y5I3Jzm8u0+rqgOTfCHJ/bv7LctOtzVc636Aqvqd9c1O8uyq2vj+5vtltV/qA1s+GBepqp6U5DlZHXn/xZz/nez8Bg6XjYcleV13n5Yk3f2NqnpNVgflCT07xnnvUldJvi+rN0Y5zzeSvC/J87Z6KC7W45I8urtfsvQgMFFVHZTVaXUP3HTXK5K8qaoOOe8XgMlsuh9ifVrWa5I8ortPXXoeLl5VfTHJkd19wtKzwERVda0kP5LkFd197qb7Hpzkrd39hUWG20JCP0RV7ZfVZVRvvZtOG9nJqurpSQ7o7qcsPQswl9APUlUnJLnf+tK3bHPrrTBvSHJ4kg8nOd/b1Xb3I5aYC5jFPvpZfiPJc6rqwd198tLDcLGemeReWR1DcfU4AA8uE1X16VzCn6fuvsnFP2pns0Y/SFV9KMmNs7q62meTnL7x/u6+1RJzsXdV9bUkj+ruVy89C0xSVU/Y8OkhSR6f5D1ZvY9Ektwpq7ORnt/dz9ji8bacNfpZXrv0AOyTM5O8f+khYJrufv55t6vqZUme293P2viYqnpyklts8WiLsEYPC1mfR3+jJL+wW67QBVutqk7J6tr2J2xa/t1J3tfdhy4z2daxRg/LuXOSuyT50ar6SC54MN6PLzIVzHJ6krsl2Xwa692SnLH5wRMJ/SDrSzs+JauLQ9wgq3313+Ja99vOyUn+fOkhYLj/keTFVbUnq3euS5I7ZnXFvKcvNdRWsul+kKp6bpL7J3l2Vv+4fy2rTcMPSPJUV2ADdqOq+pkkj83qyqFJ8tEkR3f3a5abausI/SDrU0oe3d1vrKpTk9ymuz9ZVY9Ocs/uvt/CIwKwxWy6n+U6Sc67Kt5pSa62vv3GJM9dZCIuUlX9XL69q+XAjffthvN7YStV1dVywXeJ/MpC42yZK1z8Q9hBTkpy3fXtE5Lce337TlmdysU2UlVPTPL8JMdltYvlL7O6Qt41krx0uclgjqq6YVX9bVWdmeTfknx5/XHy+r/jWaOf5S+S3DOrA06OTvInVfXIJNdL8ttLDsZePTLJUd392qp6TJIXdfenquqpSW648GwwxR9mtXXz55N8LrvwCpT20Q9WVXdIcmSST3T33yw9D+dXVWck+d7uPqmqvpTkXt39gfX5ve/p7mssPCLseFV1WpI7dveHl55lKTbdD1JVd6mqb22l6e7/190vSPLGqrrLgqOxd19Icq317ROz2sWSJN+dXbjWAZeTTyc5aOkhliT0s7wjq/27m111fR/by9uTnHdRnD9I8oKqekeSV8f59XBZeWySZ6+3lO1KNt0PUlXnJrlOd3950/KbJ3nvbrjU405SVVdIcoXuPmf9+f2z3tWS5CXdffZF/Xng4q1PNT4oyX5Jzkpyzsb7d8ProoPxBqiqv1rf7CSvqKqzNty9X5JbJvmHLR+Mi9Td5yY5d8Pnr85qbR647Dxm6QGWJvQz/Nv6v5Xkqzn/qXTfSPJ/k/z+Vg/FBVXV7ZJ8oLvPXd++UN39vi0aC8bq7pcvPcPSbLofpKqeluR53X36xT6YRax3rxze3V9a3+6sfkHbrL03AVw2quo6SR6S5KZZXQ785Ko6MsnnuvvTy053+RP6Qdb7fM/bJJyqOjzJfZN8pLttut8GquqGSU7q7l7fvlDdfeIWjQVjVdXtk7wtq6Pvb5HVKa2fqqqnJ7l5dz9oyfm2gtAPUlV/m+SN3X10VR2S5GNJrpzkkCQ/393HLjogwBZbn8nyru5+2vrAvFuvQ3+nJK/q7vEXp7KPfpY9SZ60vv1TSU5JcuMkP5vkV5II/TZTVVdKcpskh+WC1+B2ih1cerfP6qp4m30+q/cHGU/oZzkkydfWt++V5C+6++yqenuSFy83FntTVT+U5E+SXHMvd3dWZ0wAl86ZSa6+l+Xfm+RLWzzLIlwwZ5aTkhxZVVfO6g1t3rJefo0kZyw2FRfm6CSvT3L97r7Cpg+Rh8vG65I8rarOuzpeV9WNsnpHzz9baqitZB/9IFX1qCQvyuotak9Mcrv1aVy/lOQnuvseiw7I+VTV6Ulu1d2fXHoWmKqqDk3yhiS3yuqYpS9ktcn+H5LcZzecpST0w6yPML1Bkrd092nrZT+a5Gvd/feLDsf5VNWbk7ywu9+w9CwwXVXdI8ntstqS/b7ufuvCI20ZoR+iqq6a1drh3+3lviOzOsXuq1s/GRttukjOjZL8ZpIXJPlQkvNd8tYFc+DS8bq4IvRDVNVVsjqK9N4b19yr6tZJ3pPket198lLzsXIxF8nZyAVz4FLyurjiqPshuvvUqnpdkocm2biJ/iFJ3rQb/jHvEDdeegDYLbwurjjqfpZjk/znqjow+daV8h6U5GVLDsW3dfeJ530kOSqrg4FO3LT8Pkn+y7KTwhi7/nVR6Gd5S1bnjN53/fk9kxyY5K8Xm4iL8pAk79/L8uOyWgMBLr1d/7oo9IOsr3H/inw7Eg9J8mrva75tHZbky3tZ/m/ZJVfsgsub10X76Cc6NslxVXWDJD+Z1W+vbE8nJblzkk9tWn6XJJ/d+nFgrF39uuio+4Gq6r1Zbaq6Vnd/39LzsHdV9YQkT0nyq0nevl58zyTPTvLc7v6tpWaDaXbz66I1+pmOTfLCrCLCNtXdz6+qayX5naz2GSbJN5IcLfI7S1V9NMnNuttr6va1a18X/aOc6RVZvYnDHy49CBetu59cVb+Z5PvXiz563hUN2VFenL2/ORHbx659XbTpHgAGc9Q9AAwm9AAwmNAPVVVHLT0D+8ZztvN4znae3ficCf1cu+4f8wCes53Hc7bz7LrnTOgBYLBdf9T9AQdeuQ8++OpLj3GZO/vs03PAAVdeeozLxbkHXNw7vO5M55x1evY/aN5zdu7gk3i/eebp2e+K856zA0/95tIjXG6+cc4ZOXD/Ky09xmXulDM/f3J3X3tv9w3+EbxkDj746tlzh8csPQb74PQjDlh6BPbBmdey4XCnue47v7b0COyjN7//GSde2H1+AgFgMKEHgMGEHgAGE3oAGEzoAWAwoQeAwYQeAAYTegAYTOgBYDChB4DBhB4ABhN6ABhM6AFgMKEHgMGEHgAGE3oAGEzoAWAwoQeAwYQeAAYTegAYTOgBYDChB4DBhB4ABhN6ABhM6AFgMKEHgMGEHgAGE3oAGEzoAWAwoQeAwYQeAAYTegAYTOgBYDChB4DBhB4ABhN6ABhM6AFgMKEHgMGEHgAGE3oAGEzoAWAwoQeAwYQeAAYTegAYTOgBYDChB4DBhB4ABhsT+qp6eFWddmGfA8BuNCb0AMAFCT0ADLatQl8rT6iq46vqrKr6bFU9e33fc6rq41V1ZlV9pqp+q6oOXnpmANjO9l96gE2eleTRSR6f5F1Jrp3ktuv7Tk/yiCT/muT7k/xekrOSPHXrxwSAnWHbhL6qDknyuCS/3N0vXS8+Icm7k6S7f2PDwz9TVc9K8iv5DkJfVUclOSpJDjr4apdmbADY1rZN6LNaSz8oydv2dmdV3S/JLyf57iSHJNlv/bHPuvuYJMckyVUOvX5/J18DAHaCbbWP/sJU1R2TvCrJm5L8WFab838tyQFLzgUA2912WqP/aFb73O+Z5PhN9x2Z5F83br6vqhtu4WwAsCNtm9B396lVdXSSZ1fVWVkdjHfNJLdP8okk16uqn81qn/29kzxwsWEBYIfYNqFfe3KSr2Z1gN31k3wxybHd/btV9dtJXpjkiknenOTXk/yvpQYFgJ2gunf3sWhXOfT6vecOj1l6DPbB6Uc4NGMnOfNaO+JQIDa47ju/tvQI7KM3v/8Zx3X3nr3d5ycQAAYTegAYTOgBYDChB4DBhB4ABhN6ABhM6AFgMKEHgMGEHgAGE3oAGEzoAWAwoQeAwYQeAAYTegAYTOgBYDChB4DBhB4ABhN6ABhM6AFgMKEHgMGEHgAGE3oAGEzoAWAwoQeAwYQeAAYTegAYTOgBYDChB4DBhB4ABhN6ABhM6AFgMKEHgMGEHgAGE3oAGEzoAWAwoQeAwYQeAAYTegAYTOgBYDChB4DBhB4ABhN6ABhM6AFgMKEHgMGEHgAGE3oAGEzoAWCw/ZceYGl16hnZ/23HLT0G++CqSw/APvnHz31g6RHYRz/8oj1Lj8BlyBo9AAwm9AAwmNADwGBCDwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCDbbvQV9U7q+p3q+r5VfWVqvpyVT22qg6qqhdX1deq6qSqesiGP3O9qnpVVX11/fH6qrrZkn8PANgOtl3o1342yalJ7pDkOUlemOQvk3wiyZ4kL0/yv6vqiKq6UpJ3JPl6krsmuVOSzyd56/o+ANi1tmvo/7m7n97dxyd5QZKTk5zd3Ud39wlJnpGkkhyZ5AHr2z/X3R/s7o8leVSSQ5Lcd29fvKqOqqr3VtV7z85ZW/H3AYBF7L/0ABfig+fd6O6uqi8l+dCGZWdX1VeTHJbkFklunOTUqtr4Na6U5KZ7++LdfUySY5Lk0LpGX+bTA8A2sV1Df/amz/tCll1h/fGBrNbsN/vKZT8aAOwc2zX0++J9SR6Y5OTu/trSwwDAdrJd99Hviz9O8sUkr6uqu1bVjavqLuuj9h15D8CutuND391nJLlLkk8l+dMkH8vqqPyrJ/nqgqMBwOK23ab77r7bXpbdci/LDt9w+4tJfu7ynQwAdp4dv0YPAFw4oQeAwYQeAAYTegAYTOgBYDChB4DBhB4ABhN6ABhM6AFgMKEHgMGEHgAGE3oAGEzoAWAwoQeAwYQeAAYTegAYTOgBYDChB4DBhB4ABhN6ABhM6AFgMKEHgMGEHgAGE3oAGEzoAWAwoQeAwYQeAAYTegAYTOgBYDChB4DBhB4ABhN6ABhM6AFgMKEHgMGEHgAGE3oAGEzoAWAwoQeAwYQeAAYTegAYTOgBYDChB4DBhB4ABhN6ABhM6AFgMKEHgMH2X3oAYLYnfP52S4/APvr6vW679Ajsq9e/6kLvskYPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAw2P5LD7CEqjoqyVFJcnCutPA0AHD52ZVr9N19THfv6e49B+SgpccBgMvNrgw9AOwWQg8Ag40NfVU9pqo+tvQcALCksaFPcq0k37P0EACwpLGh7+6nd3ctPQcALGls6AEAoQeA0YQeAAYTegAYTOgBYDChB4DBhB4ABhN6ABhM6AFgMKEHgMGEHgAGE3oAGEzoAWAwoQeAwYQeAAYTegAYTOgBYDChB4DBhB4ABhN6ABhM6AFgMKEHgMGEHgAGE3oAGEzoAWAwoQeAwYQeAAYTegAYTOgBYDChB4DBhB4ABhN6ABhM6AFgMKEHgMGEHgAGE3oAGEzoAWAwoQeAwYQeAAYTegAYTOgBYDChB4DBhB4ABhN6ABhM6AFgMKEHgMH2X3oAYLZ/voP1iZ3mnSf9/tIjsI/2O+LC7/MTCACDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCD7ZjQV9WvVNVnlp4DAHaSHRN6AGDfXSahr6pDq+pql8XX2ofvee2qOngrvycA7DTfceirar+qundVvTLJF5Lcer38qlV1TFV9qapOrar/U1V7Nvy5h1fVaVV1z6r6cFWdXlXvqKobb/r6T6qqL6wfe2ySQzaN8CNJvrD+Xkd+p38PAJhsn0NfVbeoqt9K8i9JXp3k9CQ/nORdVVVJXp/keknum+S2Sd6V5O1VdcSGL3NQkicneUSSOyW5WpLf2/A9fibJbyZ5WpLbJfl4ksdvGuWPkzwoyVWSvKWqTqiqX9/8CwMA7GaXKPRVdc2q+qWqOi7J+5N8b5LHJjm8ux/Z3e/q7k5y9yS3SXK/7n5Pd5/Q3U9N8qkkD9nwJfdP8gvrx3wwyfOS3G39i0KS/HKSl3f3S7r7E939zCTv2ThTd5/T3W/o7gcmOTzJs9bf//iqemdVPaKqNm8FOO/vc1RVvbeq3nt2zrok/wsAYEe6pGv0v5jk6CRfT3Lz7v7x7v7T7v76psfdPsmVknx5vcn9tKo6Lcktk9x0w+PO6u6Pb/j8c0kOTHL19effl+Tdm7725s+/pbtP6e6Xdvfdk/yHJNdJ8gdJ7nchjz+mu/d0954DctBF/LUBYGfb/xI+7pgkZyd5aJIPV9VfJPmjJG/r7m9ueNwVknwxyZ338jVO2XD7nE339YY/v8+q6qCsdhU8OKt99/+c1VaB130nXw8AprhEYe3uz3X3M7v7e5L8UJLTkrwqyWer6vlVdZv1Q9+X1dr0uevN9hs/vrQPc300yR03LTvf57Xyn6rqJVkdDPg/k5yQ5PbdfbvuPrq7v7oP3xMAxtnnNeju/sfufnSSI7LapH/zJP9UVXdO8tYkf5/kdVV1n6q6cVXdqar++/r+S+roJA+rqkdW1c2q6slJ7rDpMQ9O8uYkhyZ5YJLv6u4ndveH9/XvBABTXdJN9xfQ3WcleW2S11bVYUm+2d1dVT+S1RHzv5/ksKw25f99kmP34Wu/uqpukuSZWe3z/6skL0jy8A0Pe1tWBwOecsGvAAAkSa0Olt+9Dq1r9B3qnkuPAWPV/t/x+gQLeeNJ7116BPbRfkeccFx379nbfS6BCwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAw2P5LDwDM1uecs/QI7KN7X/c2S4/APjvhQu+xRg8Agwk9AAwm9AAwmNADwGBCDwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCDCT0ADLb/0gMsoaqOSnJUkhycKy08DQBcfnblGn13H9Pde7p7zwE5aOlxAOBysytDDwC7hdADwGBCDwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCDCT0ADCb0ADCY0APAYEIPAIMJPQAMJvQAMJjQA8BgQg8Agwk9AAwm9AAwmNADwGBCDwCDCT0ADFbdvfQMi6qqLyc5cek5LgfXSnLy0kOwTzxnO4/nbOeZ+pzdsLuvvbc7dn3op6qq93b3nqXn4JLznO08nrOdZzc+ZzbdA8BgQg8Agwn9XMcsPQD7zHO283jOdp5d95zZRw8Ag1mjB4DBhB4ABhN6ABhM6AFgMKEHgMH+P2HJbansqLg8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-s7MFIHbX4S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "4ea62bd3-9d30-4d05-bccf-61bde0ab58f8"
      },
      "source": [
        "translate(df[1][99])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> io sono caduta . <end>\n",
            "Predicted translation: i fell . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9E75azdcL7w",
        "colab_type": "text"
      },
      "source": [
        "## BLEU score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGi-hKLbboI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pred_tensor(input_sentence):\n",
        "  max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "\n",
        "  #attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "  #attention_plot = []\n",
        "\n",
        "  sentence = preprocess_sentence(input_sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden,cell = tf.zeros((1, 128)),tf.zeros((1, 128))\n",
        "  enc_out, enc_hidden, enc_cell = encoder(inputs, [hidden,cell])\n",
        "\n",
        "\n",
        "  dec_hidden, dec_cell = enc_hidden, enc_cell\n",
        "  #dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 1)\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, dec_cell, _,_ = onestepdecoder(dec_input,enc_out, dec_hidden, dec_cell)\n",
        "                                                         \n",
        "    #output,dec_h,dec_c,attention_weights,_=onestepdecoder(input_to_decoder,encoder_output,dec_h,dec_c)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    #attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    #attention_plot.appeend(attention_weights.numpy())\n",
        "    #attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "    \n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "  #attention_plot = np.asarray(attention_plot)\n",
        "  return result"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC7iHarzboh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import nltk.translate.bleu_score as bleu\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def get_bleu(inp_tensor, targ_tensor):\n",
        "  random_index = random.sample(range(1, 68086), 1000)\n",
        "  bleu_score = 0\n",
        "  for index in tqdm(random_index):\n",
        "    x = input_tensor_val[index]\n",
        "    y = target_tensor_val[index]\n",
        "    out=\" \"\n",
        "    for i in x:\n",
        "      if (i!=0 and i!=1 and i!=2):\n",
        "        out += inp_lang.index_word[i] + ' '\n",
        "    inp=\" \"\n",
        "    for i in y:\n",
        "      if (i!=0 and i!=1 and i!=2):\n",
        "        inp += targ_lang.index_word[i] + ' '\n",
        "    translated = pred_tensor(out)\n",
        "    translated = translated.split()\n",
        "    translated[-1] = ''\n",
        "    translated = ' '.join(translated)\n",
        "    bleu_score += bleu.sentence_bleu([translated.split(),], inp.split())\n",
        "  return bleu_score"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbIFSGZUbtpJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "073b6131-a6aa-4f89-d157-616f6a2f2967"
      },
      "source": [
        "get_bleu(input_tensor_val, target_tensor_val)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [01:19<00:00, 12.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "628.3770478920059"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XLs36vtuS_I",
        "colab_type": "text"
      },
      "source": [
        "## Model results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw1PwrhJuWbo",
        "colab_type": "text"
      },
      "source": [
        "Best loss is achieved at the last epoch having value 0.1356\n",
        "\n",
        "BLEU score on random 1000 datapoints of test data is 628.38"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VB1jRUqZQ9AM"
      },
      "source": [
        "# Concat scoring function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2YSUzlBuvPy",
        "colab_type": "text"
      },
      "source": [
        "## Train function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1kN9ZWViQNMB",
        "colab": {}
      },
      "source": [
        "# Implement teacher forcing while training your model. You can do it two ways.\n",
        "# Prepare your data, encoder_input,decoder_input and decoder_output\n",
        "# if decoder input is \n",
        "# <start> Hi how are you\n",
        "# decoder output should be\n",
        "# Hi How are you <end>\n",
        "# i.e when you have send <start>-- decoder predicted Hi, 'Hi' decoder predicted 'How' .. e.t.c\n",
        "# from https://www.tensorflow.org/tutorials/text/nmt_with_attention#training with minor changes\n",
        "\n",
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden_h, enc_hidden_c = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden_h, dec_hidden_c = enc_hidden_h, enc_hidden_c\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * 128, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in tqdm(range(1, targ.shape[1])):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden_h, dec_hidden_c, _, _ = onestepdecoder(dec_input,enc_output, dec_hidden_h, dec_hidden_c)\n",
        "\n",
        "      loss += custom_lossfunction(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + onestepdecoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss\n",
        "\n",
        "# or\n",
        " \n",
        "# model.fit([train_ita,train_eng],train_eng[:,1:]..)\n",
        "# Note: If you follow this approach some grader functions might return false and this is fine."
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IolEjxB1uxUu",
        "colab_type": "text"
      },
      "source": [
        "## Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ff1lV0ITM6_p",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def custom_lossfunction(targets,logits):\n",
        "  # Custom loss function that will not consider the loss for padded zeros.\n",
        "  # Refer https://www.tensorflow.org/tutorials/text/nmt_with_attention#define_the_optimizer_and_the_loss_function same code used\n",
        "  mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "  loss_ = loss_object(targets, logits)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPSUIuZuuy40",
        "colab_type": "text"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AocYxo5RV2jH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(len(input_tensor_train))\n",
        "dataset = dataset.batch(128, drop_remainder=True)\n",
        "steps_per_epoch = len(input_tensor_train)//128"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbGzTpKYgRpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(inp_vocab_size=len(inp_lang.word_index)+1, embedding_size=50, input_length=50, lstm_size=128)  \n",
        "decoder = Decoder(out_vocab_size=len(targ_lang.word_index)+1, embedding_dim=50, output_length=50, dec_units=128, score_fun='concat', att_units=128)\n",
        "onestepdecoder=OneStepDecoder(len(targ_lang.word_index)+1, 50, 50, 128 ,'concat' ,128)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-wB03Ksu0vr",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIaM52lhgU8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4aaa218d-c0a7-430c-b648-7ae74816d988"
      },
      "source": [
        "# from https://www.tensorflow.org/tutorials/text/nmt_with_attention#training with minor changes\n",
        "EPOCHS = 3\n",
        "import time\n",
        "checkpoint_dir = './content/gdrive/My Drive/Colab Notebooks/Seq2Seq checkpoiints/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=onestepdecoder)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_states(batch_size=128)\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 111/111 [00:39<00:00,  2.78it/s]\n",
            "100%|██████████| 111/111 [00:40<00:00,  2.75it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 0.6878\n",
            "Epoch 1 Batch 100 Loss 0.3326\n",
            "Epoch 1 Batch 200 Loss 0.3363\n",
            "Epoch 1 Batch 300 Loss 0.3257\n",
            "Epoch 1 Batch 400 Loss 0.2916\n",
            "Epoch 1 Batch 500 Loss 0.2902\n",
            "Epoch 1 Batch 600 Loss 0.2914\n",
            "Epoch 1 Batch 700 Loss 0.2792\n",
            "Epoch 1 Batch 800 Loss 0.2681\n",
            "Epoch 1 Batch 900 Loss 0.2714\n",
            "Epoch 1 Batch 1000 Loss 0.2536\n",
            "Epoch 1 Batch 1100 Loss 0.2517\n",
            "Epoch 1 Batch 1200 Loss 0.2521\n",
            "Epoch 1 Batch 1300 Loss 0.2304\n",
            "Epoch 1 Batch 1400 Loss 0.2442\n",
            "Epoch 1 Batch 1500 Loss 0.2290\n",
            "Epoch 1 Batch 1600 Loss 0.2368\n",
            "Epoch 1 Batch 1700 Loss 0.2338\n",
            "Epoch 1 Batch 1800 Loss 0.2223\n",
            "Epoch 1 Batch 1900 Loss 0.2160\n",
            "Epoch 1 Batch 2000 Loss 0.2152\n",
            "Epoch 1 Batch 2100 Loss 0.2104\n",
            "Epoch 1 Loss 0.2698\n",
            "Time taken for epoch 1998.3184669017792 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.2149\n",
            "Epoch 2 Batch 100 Loss 0.1985\n",
            "Epoch 2 Batch 200 Loss 0.2008\n",
            "Epoch 2 Batch 300 Loss 0.1917\n",
            "Epoch 2 Batch 400 Loss 0.1899\n",
            "Epoch 2 Batch 500 Loss 0.1867\n",
            "Epoch 2 Batch 600 Loss 0.1874\n",
            "Epoch 2 Batch 700 Loss 0.2209\n",
            "Epoch 2 Batch 800 Loss 0.1864\n",
            "Epoch 2 Batch 900 Loss 0.1772\n",
            "Epoch 2 Batch 1000 Loss 0.1854\n",
            "Epoch 2 Batch 1100 Loss 0.1889\n",
            "Epoch 2 Batch 1200 Loss 0.1669\n",
            "Epoch 2 Batch 1300 Loss 0.1663\n",
            "Epoch 2 Batch 1400 Loss 0.1770\n",
            "Epoch 2 Batch 1500 Loss 0.1733\n",
            "Epoch 2 Batch 1600 Loss 0.1644\n",
            "Epoch 2 Batch 1700 Loss 0.1544\n",
            "Epoch 2 Batch 1800 Loss 0.1499\n",
            "Epoch 2 Batch 1900 Loss 0.1535\n",
            "Epoch 2 Batch 2000 Loss 0.1525\n",
            "Epoch 2 Batch 2100 Loss 0.1602\n",
            "Epoch 2 Loss 0.1785\n",
            "Time taken for epoch 1825.8541371822357 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.1679\n",
            "Epoch 3 Batch 100 Loss 0.1480\n",
            "Epoch 3 Batch 200 Loss 0.1558\n",
            "Epoch 3 Batch 300 Loss 0.1430\n",
            "Epoch 3 Batch 400 Loss 0.1241\n",
            "Epoch 3 Batch 500 Loss 0.1582\n",
            "Epoch 3 Batch 600 Loss 0.1369\n",
            "Epoch 3 Batch 700 Loss 0.1473\n",
            "Epoch 3 Batch 900 Loss 0.1464\n",
            "Epoch 3 Batch 1000 Loss 0.1402\n",
            "Epoch 3 Batch 1100 Loss 0.1282\n",
            "Epoch 3 Batch 1200 Loss 0.1368\n",
            "Epoch 3 Batch 1300 Loss 0.1229\n",
            "Epoch 3 Batch 1400 Loss 0.1310\n",
            "Epoch 3 Batch 1500 Loss 0.1236\n",
            "Epoch 3 Batch 1600 Loss 0.1204\n",
            "Epoch 3 Batch 1700 Loss 0.1426\n",
            "Epoch 3 Batch 1800 Loss 0.1199\n",
            "Epoch 3 Batch 1900 Loss 0.1126\n",
            "Epoch 3 Batch 2000 Loss 0.1076\n",
            "Epoch 3 Batch 2100 Loss 0.1221\n",
            "Epoch 3 Loss 0.1328\n",
            "Time taken for epoch 1826.3680481910706 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQMeSHoogaaj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "96452e14-a848-4413-f095-e4a43f08b8e3"
      },
      "source": [
        "# from https://www.tensorflow.org/tutorials/text/nmt_with_attention#training with minor changes\n",
        "EPOCHS = 1\n",
        "import time\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=onestepdecoder)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_states(batch_size=128)\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 0.1111\n",
            "Epoch 1 Batch 100 Loss 0.0966\n",
            "Epoch 1 Batch 200 Loss 0.1109\n",
            "Epoch 1 Batch 300 Loss 0.1079\n",
            "Epoch 1 Batch 400 Loss 0.0968\n",
            "Epoch 1 Batch 500 Loss 0.1057\n",
            "Epoch 1 Batch 600 Loss 0.1134\n",
            "Epoch 1 Batch 700 Loss 0.1007\n",
            "Epoch 1 Batch 800 Loss 0.1013\n",
            "Epoch 1 Batch 900 Loss 0.0919\n",
            "Epoch 1 Batch 1000 Loss 0.0956\n",
            "Epoch 1 Batch 1100 Loss 0.0991\n",
            "Epoch 1 Batch 1200 Loss 0.1069\n",
            "Epoch 1 Batch 1300 Loss 0.0910\n",
            "Epoch 1 Batch 1400 Loss 0.0859\n",
            "Epoch 1 Batch 1500 Loss 0.0849\n",
            "Epoch 1 Batch 1600 Loss 0.0846\n",
            "Epoch 1 Batch 1700 Loss 0.0910\n",
            "Epoch 1 Batch 1800 Loss 0.0888\n",
            "Epoch 1 Batch 1900 Loss 0.0825\n",
            "Epoch 1 Batch 2000 Loss 0.0855\n",
            "Epoch 1 Batch 2100 Loss 0.0741\n",
            "Epoch 1 Loss 0.0967\n",
            "Time taken for epoch 1824.6811904907227 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djgu65oktwTJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "54d76364-caf9-40ee-b2e5-896ace5d6da9"
      },
      "source": [
        "# from https://www.tensorflow.org/tutorials/text/nmt_with_attention#training with minor changes\n",
        "EPOCHS = 1\n",
        "import time\n",
        "checkpoint_dir = '.extra/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=onestepdecoder)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_states(batch_size=128)\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 0.0771\n",
            "Epoch 1 Batch 100 Loss 0.0785\n",
            "Epoch 1 Batch 200 Loss 0.0880\n",
            "Epoch 1 Batch 400 Loss 0.0756\n",
            "Epoch 1 Batch 500 Loss 0.0767\n",
            "Epoch 1 Batch 600 Loss 0.0704\n",
            "Epoch 1 Batch 700 Loss 0.0763\n",
            "Epoch 1 Batch 800 Loss 0.0759\n",
            "Epoch 1 Batch 900 Loss 0.0702\n",
            "Epoch 1 Batch 1000 Loss 0.0684\n",
            "Epoch 1 Batch 1100 Loss 0.0786\n",
            "Epoch 1 Batch 1200 Loss 0.0616\n",
            "Epoch 1 Batch 1300 Loss 0.0754\n",
            "Epoch 1 Batch 1400 Loss 0.0589\n",
            "Epoch 1 Batch 1500 Loss 0.0683\n",
            "Epoch 1 Batch 1600 Loss 0.0609\n",
            "Epoch 1 Batch 1700 Loss 0.0801\n",
            "Epoch 1 Batch 1800 Loss 0.0639\n",
            "Epoch 1 Batch 1900 Loss 0.0744\n",
            "Epoch 1 Batch 2000 Loss 0.0575\n",
            "Epoch 1 Batch 2100 Loss 0.0715\n",
            "Epoch 1 Loss 0.0710\n",
            "Time taken for epoch 1824.4262850284576 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QGSpcJ_CK5j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "dfc85b86-09e9-4bb1-efff-d62360386f6f"
      },
      "source": [
        "# from https://www.tensorflow.org/tutorials/text/nmt_with_attention#training with minor changes\n",
        "EPOCHS = 1\n",
        "import time\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=onestepdecoder)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_states(batch_size=128)\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 0.0602\n",
            "Epoch 1 Batch 100 Loss 0.0586\n",
            "Epoch 1 Batch 200 Loss 0.0664\n",
            "Epoch 1 Batch 300 Loss 0.0623\n",
            "Epoch 1 Batch 400 Loss 0.0612\n",
            "Epoch 1 Batch 500 Loss 0.0619\n",
            "Epoch 1 Batch 600 Loss 0.0683\n",
            "Epoch 1 Batch 700 Loss 0.0634\n",
            "Epoch 1 Batch 800 Loss 0.0591\n",
            "Epoch 1 Batch 900 Loss 0.0553\n",
            "Epoch 1 Batch 1000 Loss 0.0589\n",
            "Epoch 1 Batch 1100 Loss 0.0512\n",
            "Epoch 1 Batch 1200 Loss 0.0613\n",
            "Epoch 1 Batch 1300 Loss 0.0509\n",
            "Epoch 1 Batch 1400 Loss 0.0542\n",
            "Epoch 1 Batch 1500 Loss 0.0509\n",
            "Epoch 1 Batch 1600 Loss 0.0497\n",
            "Epoch 1 Batch 1700 Loss 0.0703\n",
            "Epoch 1 Batch 1800 Loss 0.0455\n",
            "Epoch 1 Batch 1900 Loss 0.0533\n",
            "Epoch 1 Batch 2000 Loss 0.0521\n",
            "Epoch 1 Batch 2100 Loss 0.0486\n",
            "Epoch 1 Loss 0.0545\n",
            "Time taken for epoch 1828.3004620075226 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKz6U8dFR-Tc",
        "colab_type": "text"
      },
      "source": [
        "## Model summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R88981UYSBQD",
        "colab_type": "text"
      },
      "source": [
        "Model is trained for 6 epochs.\n",
        "\n",
        "Optimizer used is Adam with constant learning rate mentioned below.\n",
        "\n",
        "  *   First 6 epochs on default learning rate 0.01.\n",
        "\n",
        "Batch size used is 128.\n",
        "\n",
        "Embed size = Input length = Output length = 50\n",
        "\n",
        "Decoder units = Lstm units = Attention units = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_kmtwSNRvhg",
        "colab_type": "text"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSmlL1HHQkNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  #Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate code taken from same\n",
        "\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kU3-KXoRAuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(input_sentence):\n",
        "  #https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate taken from here with minor changes\n",
        "  '''\n",
        "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "         Save the attention weights\n",
        "         And get the word using the tokenizer(word index) and then store it in a string.\n",
        "  E. Call plot_attention(#params)\n",
        "  F. Return the predicted sentence\n",
        "  '''\n",
        "  max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "  #attention_plot = []\n",
        "\n",
        "  sentence = preprocess_sentence(input_sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden,cell = tf.zeros((1, 128)),tf.zeros((1, 128))\n",
        "  enc_out, enc_hidden, enc_cell = encoder(inputs, [hidden,cell])\n",
        "\n",
        "\n",
        "  dec_hidden, dec_cell = enc_hidden, enc_cell\n",
        "  #dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 1)\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, dec_cell, attention_weights,_ = onestepdecoder(dec_input,enc_out, dec_hidden, dec_cell)\n",
        "                                                         \n",
        "    #output,dec_h,dec_c,attention_weights,_=onestepdecoder(input_to_decoder,encoder_output,dec_h,dec_c)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    #attention_plot.appeend(attention_weights.numpy())\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "  #attention_plot = np.asarray(attention_plot)\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GltAThLxRBAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention= predict(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnLis2QWRDvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn2Ym1CgRGBv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "7dd72adb-b820-4143-ac0a-fee9e97c4a5a"
      },
      "source": [
        "translate(df[1][0])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> ciao ! <end>\n",
            "Predicted translation: hello ! <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BgLwg-fRIJY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "928f6ab4-ba77-4c2a-bd69-4dc3ba4203eb"
      },
      "source": [
        "translate(df[1][99])"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> io sono caduta . <end>\n",
            "Predicted translation: i fell . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfNtQqYWRO3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "37620b83-2ee7-4f0f-f269-600394b742f1"
      },
      "source": [
        "translate(df[1][1000])"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> tom ha mentito . <end>\n",
            "Predicted translation: tom lied . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpP_pXOSRyeN",
        "colab_type": "text"
      },
      "source": [
        "## BLEU score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M24_rxGRRRlp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pred_tensor(input_sentence):\n",
        "  max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "\n",
        "  #attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "  #attention_plot = []\n",
        "\n",
        "  sentence = preprocess_sentence(input_sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden,cell = tf.zeros((1, 128)),tf.zeros((1, 128))\n",
        "  enc_out, enc_hidden, enc_cell = encoder(inputs, [hidden,cell])\n",
        "\n",
        "\n",
        "  dec_hidden, dec_cell = enc_hidden, enc_cell\n",
        "  #dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 1)\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, dec_cell, _,_ = onestepdecoder(dec_input,enc_out, dec_hidden, dec_cell)\n",
        "                                                         \n",
        "    #output,dec_h,dec_c,attention_weights,_=onestepdecoder(input_to_decoder,encoder_output,dec_h,dec_c)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    #attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    #attention_plot.appeend(attention_weights.numpy())\n",
        "    #attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "    \n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "  #attention_plot = np.asarray(attention_plot)\n",
        "  return result"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdXKQhu6Re7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import nltk.translate.bleu_score as bleu\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def get_bleu(inp_tensor, targ_tensor):\n",
        "  random_index = random.sample(range(1, 68086), 1000)\n",
        "  bleu_score = 0\n",
        "  for index in tqdm(random_index):\n",
        "    x = input_tensor_val[index]\n",
        "    y = target_tensor_val[index]\n",
        "    out=\" \"\n",
        "    for i in x:\n",
        "      if (i!=0 and i!=1 and i!=2):\n",
        "        out += inp_lang.index_word[i] + ' '\n",
        "    inp=\" \"\n",
        "    for i in y:\n",
        "      if (i!=0 and i!=1 and i!=2):\n",
        "        inp += targ_lang.index_word[i] + ' '\n",
        "    translated = pred_tensor(out)\n",
        "    translated = translated.split()\n",
        "    translated[-1] = ''\n",
        "    translated = ' '.join(translated)\n",
        "    bleu_score += bleu.sentence_bleu([translated.split(),], inp.split())\n",
        "  return bleu_score"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qokhti6SrPU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "49b35cce-dc45-45af-d81f-e9ce18e657e6"
      },
      "source": [
        "get_bleu(input_tensor_val, target_tensor_val)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [01:49<00:00,  9.13it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "718.5695864681999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iacdP163SiP-",
        "colab_type": "text"
      },
      "source": [
        "## Model Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7akGi1DSkfc",
        "colab_type": "text"
      },
      "source": [
        "Best loss is achieved at the last epoch having value 0.0545\n",
        "\n",
        "BLEU score on random 1000 datapoints of test data is 718.57"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0f7cvkJRqEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}